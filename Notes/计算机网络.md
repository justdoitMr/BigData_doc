计算机网络总结

***

- [物理层](#物理层)
- [数据链路层](#数据链路层)
- [网络层](#网络层)
- [运输层](运输层)
- [应用层](#应用层)

***

## 一，物理层

功能：

![物理层大纲](G:\md文件\jpg\物理层.png)

### 一，名词解释

- 数据：数据是指传送信息 的实体。
- 信号：信号是指数据的电器或者电磁表现（数据和数字都用数字的或者模拟的来形容）。
- 码元：码元是指用一个固定时长的信号波形（数字脉冲）标示以为k进制的数据，代表不同离散数值的基本波形，是数字通信中数字信号的基本单位，这个时长内的信号称为k进制码元，而该时长称为码元宽度，一个码元可以携带多个比特信息。
- 信源：信源是指产生和发送数据的源头，
- 信宿：指接受数据的终点。
- 信道：指信号的传输媒体，按照传输信号形式的不同分为传送模拟信号的模拟信道和传送数字信号的数据信道，按照传输介质分为无线信道和有线信道，基带信号将数字信号1和0直接用两种不同的电压标示，然后传送到数字信道上进行传输（基带传输），带宽信号将基带信号进行调制后形成频分复用的模拟信号，然后在模拟信道上进行传输。
- 带宽：在计算机网络中，带宽用来表示单位时间内从网络的一点到另一点通过的最高数据传输率（也即速率）。
- 速率：数据率，指的是数据的传输速率，标示单位时间内传输的数据量，可以用码元速率和信息传输速率来标示。
  - 码元传输速率：标示单位时间内通过的码元个数。也可以是脉冲个数或者信号的变化次数，码元速率与进制数无关。
  - 信息传输速率：标示单位时间内通过的比特数，单位bit/s。

### 二，电路交换，数据报交换，分组交换的比较

1. 电路交换：连接建立，数据通信，连接释放

   优点：

   1. 通信时延比较小。
   2. 有序传输数据。
   3. 没有冲突发生。
   4. 使用范围比较广。
   5. 实用性强。
   6. 控制比较简单。

   缺点：

   1. 建立连接需要花费较长时间。
   2. 线路独占，使用效率很低。
   3. 灵活性比较差。
   4. 难以规格化。

   note:电路一旦建立后，电路上的任何节点都采用直通的方式发送数据和接收数据，显然比分组转发时延小很多。

2. 报文交换：

   note:报文交换的单位是报文，报文携带有目的地地址，原地址等信息，报文在转发过程中使用的是存储转发机制。

   优点：

   1. 不需要建立连接，不存在建立连接时延。
   2. 动态的分配线路，发送数据是不需要一直占用整个链路。
   3. 提高线路的可靠性，某一个节点发生故障，可重新选择线路发送。
   4. 提高线路的利用率，通信双方不必一直占用通信线路，而是一段一段的占用物理信道。
   5. 提供多目标服务。

   缺点：

   1. 由于报文在转发过程中使用存储转发技术，因此难免会带来各种时延。
   2. 报文交换对报文的大小没有限制，因此要各个节点必须有较大的缓存空间。

3. 分组交换

   note:分组交换是为了解决报文交换中报文段过大的问题，把一个报文段分割成组，每一组自由的在网络上利用存储转发机制进行转发。

   优点：

   1. 没有建立连接时延。
   2. 线路利用率很高，通信双方分时占用每一段物理信道，提高利用率。
   3. 简化了存储管理，相对于报文，分组小得多，因此每个节点的缓存空间相对较小方便管理。
   4. 加速传输，分组是逐个传输的，因此各个分组可以并行进行传输。
   5. 减少报文出错和重发的概率。

   缺点：

   1. 存在传输时延。
   2. 需要传输额外的信息，增加了处理时延。
   3. 分组采取数据报服务时候，可能出现分组不按序到达，分组丢失等情况。

   总结：当传输的数据量很大并且传输时延远远大于连接时延，用电路交换比较好，端到端的通路由很多链路组成，采用分组交换比较好，其中分组交换比报文交换时延小，适合计算机之间突发式通信。

### 三，数据报和虚电路的比较(分组交换的两种方式)

|                    | 数据报服务                                               | 虚电路服务                                       |
| ------------------ | -------------------------------------------------------- | ------------------------------------------------ |
| 连接建立           | 不需要                                                   | 需要                                             |
| 目的地址           | 每一个分组都有完整的目的地址                             | 仅仅在连接建立时使用，之后每一个分组使用虚电路号 |
| 路由选择           | 每一个分组独立的选择路由                                 | 属于同一条虚电路的分组按照同一路由转发           |
| 分组顺序           | 不保证分组的有序到达                                     | 保证分组的有序到达                               |
| 可靠性             | 不保证可靠通信，可靠通信有主机来保证                     | 可靠性由网络保证                                 |
| 对网络故障的适应性 | 出故障的节点丢失分组时，其他节点动态变化路由可以正常传输 | 所有经过该节点的虚电路都不可以正常工作           |
| 差错控制和流量控制 | 由用户主机进行流量控制，不保证数据的可靠性               | 可以由分组交换网负责，也可以用户主机负责         |

### 四，物理层设备

1. 中继器：
   1. 中继器又称为转发器，主要功能是将信号整型放大再转发出去，以消除信号由于经过一长段电缆，因噪卢或其他原因而造成的失真和衰减，使信号的波形和强度达到所需要的要求，来扩大网络传输的距离。其原理是信号再生〈而不是简单地将衰减的信号放大〉。中继器有两个端口，将一个端口输入的数据从另一个端口发送出去，但仅作用于信号的电气部分，而不管数据中是否有错误数据或不适于网段的数据。
   2. 中继器在局域网环境下用来扩大网络规模的最简单最廉价的互联设备。使用中继器连接起来的几个网段仍然是一个局域网.一般情况下，中继器的两端连接的是相同的媒体，但有的中继器也可 以完成不同媒体的转接工作。但由于中继器工作在物理层，所以它不能连接两个具有不同速率的局域网. 中继器两端的网络部分是网段，而不是子网，中继器若出现故障， 对相邻的个网段的工作都将产生影响。
      - 放大器和中继器都是起放大作用，只不过放大器放大的是模拟信号，原理是将衰减的信号放大，中继器放大的是数字信号，原理是将衰减的信号整形再生，如果某个网络设备具有存储转发的功能，那么可以认为该设备可以连接两个不同的协议，如果该网络设备没有存储转发功能， 则认为该设备不能连接两个不同的协议。中继器是没有存储转发功能的，因此中继器不能连接两个速率不同的网段，中继器两端的网段一定要是同一个协议。
2. 集线器：
   1. 集线器( Hub ) 实质上是一个多端υ口的中继器，也工作在物理层。在Hub 工作时，当一个端口接收到数据信号后， 由于信号在从端口至Hub 的传输过程中已有 衰减，所以Hub 便将该信号进行整形放大，使之再生〈恢复)到发送时的状态，紧接着转发到其他所有(除输入端口以外)处于工作状态的端口上.如果同时有两个或多个端口输入，则输出时会发生冲突，会使这些数据都成为无效的。从Hub 的工作方式可以看出，它在网络中只起到信号放大和转发作用，其目的是在扩大网络的传输范围， 而不是信号的定向传送能力即信号传输的方向是固定，是一个标准的共享式设备.
   2. 由Hub 组成的网络是共享式网络，在逻辑上仍然是一个总线网. Hub 每个端口连接的网络部分是同一个网络的不同网段.同时Hub 也只能够在半双工下工作， 网络的吞吐率因而受到限制。
   3. 注意: 多台计算机同时通信必然会发生，所以集线器不能分割冲突域，所有集线器端口都属于同一个冲突域。集线器在一个时钟周期中只能传输一组信息，如果一台集线器连接的机器数目较多，并且多台机器经常需要同时通信，将导致信息的碰撞， 使得集线器的工作效率很差。比如一个带宽为10Mb/s 的集线器上连接了8 台计算机，当这8 台计算机同时工作时，每台计算机真正所拥有的带宽为10/8 Mb/s=1.25Mb/s。

## 二，数据链路层

![数据链路层](G:\md文件\jpg\数据链路层.png)

### 一，数据链路层功能

1. 为网络层提供服务
   - 数据链路层在物理层的基础之上向网络层提供服务，主要是加强物理层传输原始比特流的功能，将物理层提供的可能出错的物理连接改造为逻辑上无差错的数据链路。主要三种服务：无确认无连接的服务，有确认无连接的服务，有确认面向连接的服务。
2. 链路管理
3. 帧定界，帧同步，透明传输
4. 透明传输(比特填充，字符填充，字符计数法，违规编码法)
5. 差错控制（循环冗余码）

### 二，流量控制与可靠传输机制

1. 流量控制：流量控制是端到端直接的流量控制（注意和拥塞控制区分），是指限制发送端向网络上发送数据的速率使得接收端来得及接收数据，是局部性问题，而非全局问题，常见有停止等待协议，活动窗口协议。

   - 停止等待协议停止等待协议相当于发送端和接收端维持的窗口都是1，发送端每发送一个帧，都要等待接收端返回一个确认帧以后再发送下一帧。

     - 在停止等待协议中可能出现两种差错：
       - 到达接收端的帧后帧被破坏，那么接收端就简单的丢弃帧即可，所以此时在发送端要维持一个计时器，等到超时没有收到接收端发送的确认帧后就重新传输此帧。
       - 另一种情况是接收端返回的确认帧在返回的途中被破坏，此种情况发送端也收不到确认帧，因此会进行超时重传，这种情况接收端会收到重复帧，会简单的丢弃，重新返回一个确认帧，但重新发送的确认帧需用ack0和ack1来标示，接收端在收到有误的确认帧，就重新传输此数据帧。

   - 后退N帧协议（GBN）

     为了解决单帧确认中效率低下的问题，有了后退N帧协议，后退N帧协议运行发送端每次发送多个数据帧，不必等待接收方发送一个确认帧之后再发送数据帧，当接收方收到失序的数据帧以后，要求发送方重新发送最后的一个确认帧后未确认的帧，或者当发送方发送了n个帧以后，发现该n个帧的前一个帧在计时器超时后没有按时返回确认帧，就认为n个帧前的帧全部丢失，于是重新发送n帧以前的帧以及这n个帧，接收方只允许接收按顺序到达的帧，在这种协议下，相当于发送方维持的发送窗口大于1，而接收窗口的值为1.后退N帧协议的接收窗口大小为1，保证接收方只能按顺序接收帧，如果采用n比特对帧进行编号，发送窗口的大小为1<=W~t~<=2^n^-1。

     - 缺点：当信道的传输质量不高时，会导致重传许多帧，因此信道质量不好时用后退N帧协议还不如停止单帧确认的协议好。

   - 选择重传协议（SR）

     为进一步提高信道利用率，可以设法只重新传输出现差错的帧，但有必须加大接收窗口的缓存空间，ARQ协议要求为每个发送缓冲区设置一个计时器，当缓冲区的帧出现超时时候，就会重新传输此帧。一旦接收方发现帧出错，就会发送一个出错NAK帧，要求发送方对出错的帧进行重传。

     - 选择重传协议的发送窗口和接收窗口都大于1，一次可以发送和接收多个帧，若果采用n比特对帧编号，那么接收窗口和发送窗口的大小为W~tmax~=W~rmax~=2^n-1^.

   - 信道的利用率：在一个周期内实际发送数据的时间/周期。

     - =(L/C)/T,L是在一个周期内实际发送的比特数，C是数据发送率,T是周期。
     - 信道吞吐率=信道利用率*发送方的发送速率。

### 三，介质访问控制

介质访问控制层的任务：为使用介质的每个节点隔离来自同一条信道上面其他节点所传送的信号，以协调节点的传输，用来决定广播信道中信道的分配的协议属于数据链路层的一个子层，称为介质访问控制（MAC），常用的有三种，信道划分介质访问控制，随机访问介质访问，轮询访问介质访问控制。

1. 信道划分介质访问控制：

   - 频分多路复用（FDM）
   - 时分多路复用（TDM）
   - 波分多路复用（WDM)
   - 码分多路复用（CDM）

2. 随机访问介质访问控制

   1. ALOHA协议：

      - 纯ALOHA协议：当网络中任何一个站点要发送数据时，不需要监听就可以直接发送，当遇到冲突就随机等待一个时间继续发送数据，
      - 时隙ALOHA协议：时隙的ALOHA协议把许多站点的时间同步起来，划分成许多的时间片，每个站点发送数据只在时间片内，每个站点刚好可以在一个时间片内发送完数据，如果发生碰撞，等待若干个时间片继续发送。

   2. CSMA协议：

      - 如果每个站点在发送数据前先监听一下信道是否空闲，如果空闲就发送数据，否则等待随机时间在发送，根据监听方式和监听到信道空闲时处理方式不同分为三种：

        - 1坚持：监听到信道空闲立即发送数据，信道忙的话则等待，1坚持中的1是信道空闲就立即发送，信道忙就等待。

          note:传播时延对1坚持影响较大。

        - 非坚持：监听到信道空闲就立即发送数据，监听到信道忙就放弃监听，等待一个时间继续发送数据。

          note:非坚持在监听到信道忙后就立即放弃监听，这避免了多个信道同事发送产生碰撞的概率，但是大大增加了数据的传播时延。

        - p坚持，监听到信道空闲后就以概率p发送数据，以概率1-p推迟一个时隙发送数据，监听到信道忙后，就等待一个时隙继续监听，p坚持是1坚持和非坚持的折中。

        | 信道状态 | 1坚持        | 非坚持                         | p坚持                                      |
        | -------- | ------------ | ------------------------------ | ------------------------------------------ |
        | 空闲     | 立即发送数据 | 立即发送数据                   | 以概率p发送数据，1-p推迟下一个时隙发送数据 |
        | 忙       | 继续监听信道 | 放弃监听，推迟一个时隙继续监听 | 持续监听                                   |

   3. CSMA/CD协议（载波监听，多路碰撞，碰撞检测）

      1. CSMA/CD协议在发送数据前先监听信道是否空闲，如果信道空闲就立即发送数据，一边发送数据一边监听信道，如果信道空闲就停止发送数据，用二进制退避算法等待一个时隙继续监听信道发送数据。所以协议的工作方法可以概括为先听后发，边听边发，但是总线的传播时延对协议的影响很大。

         - 设想一下这种情况，A向B发送数据，假设单程时延为a,A在t=0开始发送数据，而B在a-b时检测到信道空闲，于是开始发送数据，经过b/2时间，B检测到信道发生碰撞，于是停止发送数据，而A在2a-b时间检测到了信道发生碰撞，于是停止发送数据，所以，由于信道传播的时延会对两端检测到信道是否发生碰撞有很大的影响，所以csma/cd协议不能支持全双工通信，只能在半双工下通信。以上讨论中，由于A在2a-b时间没检测到信道发生碰撞，所以，假设在b很小的情况下，A在2a时间内，也就是信道的往返时间就可以检测到信道是否发生碰撞，如果在往返时间2a内没有发生碰撞，在以后A发送数据是不可能发生碰撞的，所以往返时间2a也称为争用期，如果在争用期内没有发生碰撞，那么A就占据了信道的使用权，以后发生数据不可能在发生碰撞，为了在A发送完数据之前就可以监听到信道是否发生了冲突，即帧的传输时延最少两倍于帧在信道上面的传播时延，所以就产生了最小帧长度概念，如果在帧发送完前监听到信道忙，就立即放弃发送，由此得到最小帧长度是=总线传播时延*2*数据传输速率。

         ![查看源图像](https://cn.bing.com/th?id=OIP.7kapEb8LA1ysqUPYtwPX0AHaFY&pid=Api&rs=1)

      2. 退避算法：

         1. CSMA/CD协议在发生冲突时执行二进制退避算法，具体如下：

            - 一般取总线的往返时间作为争用期。
            - 定义参数k作为重传的次数。但是k不超过10，k=min[重传次数，10]，当重传次数大于10的时候，k就等于10不在变化。
            - 从离散集合[0,1,2........2^k^-1]中选取一个数r,重传的退避时间就是r倍的基本退避时间，2ra。
            - 当重传达到16此仍然不能成功时，就认为网络拥挤，向高层报告出错。

            二进制退避算法的好处：使用二进制退避算法重传所需要的时间随着重传的次数而增大，可以大大降低发生碰撞的概率，所以也称为动态退避算法。

   4. CSMA/CA协议

      1. CSMA/CD协议应用于有线的局域网，但是在无线局域网应用上，使用CSNA/CD协议在碰撞检测方面不是很好，主要有两个原因：
         - 接收信号的强度往往会远远小于发送信号的强度，信号在无线的介质上传输变化失真很大，因此去检测无线信道是否发生碰撞代价很大。
         - 在无线局域网中并非所有的站都可以听见对方，即存在隐蔽站问题。
      2. 无线局域网使用CSMA/CA协议，尽量在传输数据过程中避免碰撞，而不是检测碰撞，当发生碰撞时，该协议也使用二进制退避算法来处理。
         - 避免碰撞的方法：
           预约信道，在发送数据的站点发送数据前先向信道上其他主机通知自己所要发送数据的长度，以便让其他站点在此时间不要发送数据来避免碰撞。
         - ACK帧，所有的站点在收到向自己发送的数据以后都要返回一个确认帧给发送站，发送站才可以继续发送数据，如果发送站在规定时间内没有收到确认帧的话，就重新发送数据帧。
         - RTS/CTS主要用来解决隐蔽站的问题。
      3. CSMA/CA和CSMA/CD协议的区别：
         - csma/cd协议是检测冲突，检测到冲突以后就立即停止发送数据等到信道空闲时再发送数据，但是无法避免冲突，而csma/ca协议是尽最大努力避免冲突，信道上有冲突，但尽力避免。
         - 传输介质不同：csma/cd协议使用总线型以太网，而csma/ca协议用无线局域网802.11a/b/g/n.
         - 检测方式不同：csma/cd协议使用电缆中的电压范围来检测，而csma/ca协议使用能量检测，载波检测，能量载波混合检测方式等。
         - 而csma/ca协议在本节点出没有冲突，但是不带表在其他节点处也没有冲突。
      4. 而csma/ca协议的思想是在发送数据前通知其他节点自己要发送数据，不允许其他节点也发送数据，csma/cd协议思想是在发送数据前先监听，没有冲突就发送数据，有冲突等待。

   5. 轮询访问介质访问控制，令牌传递协议，主要用在令牌环局域网中。

      - 局域网中有一个帧充当令牌，没有数据帧时再各个主机之间相互传递，当有主机要发送数据时就获得令牌，而在此期间其他主机没有获得令牌不允许发送数据，当令牌传递回发送方时，由发送方来撤销该帧，释放令牌供其他主机来使用，传输介质物理上不必是一个环，但是逻辑上必须是一个环。



###  四，局域网

1. 概念:局域网是指在一个较小的地理范围内，将各种计算机，外部设备，和数据库系统等通过双绞线电缆等连接起来，组成资源和信息共享的计算机互连网络。

2. 主要特点：

   - 局域网常常为一个单位所有，并且在地理范围内站点个数有限。
   - 所有站点共享较高的总带宽。
   - 较低的时延和误码率。
   - 各个站点是平等关系而非主从关系。
   - 可以进行广播和组播。

3. 局域网的三个决定要素：拓扑结构，传输介质，和介质访问控制方式

   三种局域网的拓扑结构：星型结构，总线型结构，环形结构，

   局域网的介质访问控制方式有：CSMA/CD协议，令牌总线和令牌环，前两种主要用于总线型，后一种用于环形。

   两种特殊局域网的拓扑结构实现：以太网，逻辑拓扑总线型，物理拓扑星型的。

   令牌环，逻辑拓扑环形，物理拓扑星型。

   局域网只使用iso参考模型的下两层：数据链路层和物理层。其中在链路层又分为逻辑链路控制（LLC）和介质访问控制子层，与接入传输媒体有关的内容都放在传输媒体自层，主要功能包括：组帧和拆卸帧，比特传输和差错检验，透明传输，LLC子层与传输媒体媒体无关，他向网络层提供无确认无连接，面向连接，待确认无连接，高速传输等四种不同连接服务。

4. 以太网和ieee 802.3

   1. 以太网采用无连接的工作方式，不对发送的数据帧进行编号，也不要求你

      接收方返回确认帧，即以太网提供尽最大努力的交付，提供不可靠的服务对于差错的纠正由高层来处理。

   2. 一台网传输介质： 

      - 10base5:粗缆，总线型拓扑结构，最大长度500米。
      - 10base2:细缆，总线型拓扑结构，最大长度185米。
      - 10base-T:非屏蔽双绞线，星型拓扑结构，最大长度100米。
      - 10base-fl:光纤，点对点通信，最大长度2000米。

   3. 以太网的MAC帧：每一块网络适配器都有一个6字节MAC硬件地址，高24位是厂商的代码，低24位有厂商进行自行分配。由于以太网使用的是广播通信，因此以太网的网卡每收到一个MAC帧，首先用硬件检查帧中的MAC地址，如果发往本站就收下，否则就丢弃。

      以下就是以太网的帧格式，前面8个字节中有7个字节是前同步码，后面一个字节是真开始定界附，以太网帧不需要帧结束符，应为以太网发送帧的时候会每隔一个间隙在发送帧，所以连续收到的比特流一定属于同一个帧。

      !["以太网mac帧"的图片搜索结果](https://bbsmax.ikafan.com/static/L3Byb3h5L2h0dHBzL2ltYWdlczIwMTguY25ibG9ncy5jb20vYmxvZy8xMzM0MTU3LzIwMTgwNS8xMzM0MTU3LTIwMTgwNTEzMTgyMzU0Njg5LTIwMjMzMzU3NDEucG5n.jpg)

   4. 高速以太网：速率达到100Mb/s的以太网称为高速以太网。

      - 100BASE-T以太网：是在双绞线上传送100MB/s的基带信号，拓扑结构是星型，使用CSMA/CD协议，这种以太网可以再全双工和半双工下工作，在全双工下不使用CSMA/CD协议。
      - 吉比特以太网：速率达到1Gb/s的以太网称为吉比特以太网，这种以太网可以再全双工和半双工下工作，在全双工下不使用CSMA/CD协议，在半双工下使用CSMA/CD协议。
      - 10吉比特以太网：10吉比特以太网用光纤作为传输媒体，但是只能在全双工方式下工作，不使用CSMA/CD协议。

5. 无线局域网（有固定基础设施的无线局域网和无固定基础设施无线局域网自组织网络）

   1. 令牌环网：令牌环网的每一站通过电缆与环接口干线耦合器（TCU)相连接，TCU主要作用是传递所有经过的帧，为接入站发送和接收数据提供接口，TCU的状态也有两个，收听状态和发送状态，数据总是在某个特定的方向上从上一个TCU到下一个TCU逐比特的发送信息，每一个TCU重新产生并且重传每一个比特，令牌环网的令牌是一个特殊的帧，本身并不包含数据，仅仅是控制信道的使用，确保同一时刻仅有一台主机独占信道，，因此令牌环网不会发生碰撞。

      !["令牌环网"的图片搜索结果](https://gss1.bdstatic.com/-vo3dSag_xI4khGkpoWK1HF6hhy/baike/c0%3Dbaike80%2C5%2C5%2C80%2C26/sign=6cd895fc6c81800a7ae8815cd05c589f/8601a18b87d6277f23af5e4b28381f30e924fc00.jpg)

      令牌环网在物理上是星型结构，但逻辑上是环形结构。

### 五，广域网

1. 广域网通常是指覆盖范围很广的长距离网络，广域网是因特网的核心部分，其任务是长距离运送主机发送的数据，但是广域网不等于互联网，互联网可以连接各种异构的网络（即可以连接局域网，又可以连接广域网），通常使用路由器来连接，广域网由一些节点交换机和连接这些节点交换机的链路组成，（节点交换机是在单个的网络中转发分组，而路由器是在多个异构的网络之间转发分组，）节点之间都是点到点的连接，通常一个节点交换机和多个节点交换机相连接。

   |          | 广域网                                                       | 局域网                   |
   | -------- | ------------------------------------------------------------ | ------------------------ |
   | 覆盖范围 | 很广，通常是跨区域                                           | 很小，通常在一个区域内   |
   | 连接方式 | 节点之间都是点到点的连接，但为了可靠性，一个节点往往和多个节点交换机相连接 | 普遍采用多点接入的方式   |
   | osi层次  | 三层：网络层，数据链路层，物理层                             | 两层：数据链路层，物理层 |
   | 着重点   | 强调资源共享                                                 | 强调数据传输             |

   共同点：广域网和局域网都是互联网的重要组成部分，从互联网角度看，二者是平等关系，非包含关系。连接在一个局域网或者一个广域网上的主机在通信时仅仅使用物理地址。

2. 两个典型的协议（ppp协议和hdlc协议）

   - ppp协议：ppp协议是串行通路的面向字节的协议

     组成：链路控制协议（LCP）,一种扩展的链路控制协议，用于建立，配置，测试和管理数据连接。

     ​	网际控制协议（NCP），ppp协议允许同时采用多种网络层协议，每个不同的网络层协议都要一个相应的

     NCP来配置，为网络层协议建立和配置逻辑连接。

     一个将ip数据报封装到串行的方法：ip数据报被封装到ppp帧的数据部分，这个数据部分受到MTU的限制。

   - 特点：

     - ppp协议是点对点的，并不是总线型，因此不需要CSMA/CD协议。
     - ppp协议提供检错功能但是不提供纠错功能，只能保证无差错接收，是不可靠的传输协议，因此也没有序号和确认机制。
     - ppp协议是在全双工方式下工作。
     - ppp协议两端的网络层可以运行不同的协议，但仍然可以使用ppp协议进行通信。
     - ppp协议是面向字节的协议，因此可以使用两种透明传输机制，字节填充和字符填充。

   - HDLC协议（高级数据链路控制）

     - 高级数据链路控制是iso制定的面向比特的数据链路层协议，在全双工方式写通信，有较高的数据传输速率，采用crc冗余检验，对帧进行编号，防止漏发或者重发，传输的可靠型比较高。

     - 两种基本配置：

       - 非平衡配置的特点是一个主站控制整个链路工作。
       - 平衡配置的特点是链路两端的两个站是复合站，每一个站都可以平等的发送数据和传输数据，而不需要得到对方的认可。

     - 站：主站：主站控制链路层的操作，主站发出的帧为命令帧，从站受控于主站，按照主站命令进行操作，发出的帧为相应帧，复合站就可以发送命令，又可以相应命令。

     - 数据操作方式：

       - 正常相应方式：是一种非平衡结构的操作方式，即主站传输数据，从站接收数据，但是只有通过主站的允许后从站才可以接收数据。
       - 异步平衡方式：是一种平衡的操作方式，这种方式两端的复合站都可以传送和接收数据。
       - 异步相应方式：是一种非平衡的操作方式，从站即使未得到主站的允许，也可以接收数据。

     - 帧格式：

       !["hdlc帧"的图片搜索结果](data:image/png;base64,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)

       - HDLC有三种帧：
         - 信息帧：第一位是0，用来传输数据或者用捎带确认技术对帧进行确认。
         - 监督帧：第一二位是10，用来流量控制，差错控制，执行对信息帧的确认请求重发和暂停等功能。
         - 无编号帧：第一二位全是1，用来建立连接拆除连接等。

     - ppp和HDLC的对比

       - ppp协议是面向字节的，HDLC是面向比特的。
       - ppp帧比HDLC帧多了两个字节的协议字段。
       - ppp帧不使用确认和序号，只保证无差错的接收，而端到端的差错由高层来保证，HDLC使用序号和确认机制，保证了端到端的可靠传输。

### 六，数据链路层设备

#### 6.1，网桥的概念及其基本原理

- 两个或多个以太网通过网桥连接起来后，就成为一个覆盖范围更大的以太网，而原来的每个以太网就可称为一个网段. 网桥工作在链路层的MAC 子层，可以便以太网各网段成为隔离开的碰撞域。如果把网桥换成工作在物理层的转发器，就没有这种过滤通信的功能。由于各网段的相对独立， 一个网段的故障不会影响到另一个网段的运行。
- 注意:网桥处理数据的对象是帧，所以它是工作在数据链路层的设备，中继器、放大器处理数据的对象是信号， 所以它是工作在物理层的设备.
- 网络l 和网络2 通过网桥连接后，网桥接收网络1发送的数据帧，检查数据帧中的地址， 如果是网络2 的地址，就转发给网络2; 如果是网络1 的地址，就将其丢弃，因为源站和目的站处在同一个网段，目的姑能够直接收到这个帧而不需要借助网桥的转发。

#### 6.2，网桥的基本特点

- 网桥的基本特点: ①网桥必须具备寻址和路径选择能力，以确定帧的传输方向: ②从源网络接收帧，以目的网络的介质访问控制协议向目的网络转发该帧: ③网桥在不同或相同类型的LAN之间存储并转发帧，必要时还进行链路层上的协议转换。提醒读者， 一般情况下，存储转发类设备都可以进行协议转换， 即连接的两个问段可以使用不同的协议:④网桥对所接收到的帧不做任何修改，或只对帧的封装格式做很少的修改: ⑤网桥可以通过执行帧翻译互联不同类型的局域网，即把原协议的信息段的内容作为另一种协议的信息部分封装在帧中: ⑥网桥应有足够大的缓冲空间， 因为在短时间内帧的到达速度可能高于转发速度。
- 网桥的优点: ①过滤通信量;②扩大了物理范围:③可使用不向的物理层: @可互联不同类型的局域网: ⑤提高了可靠性;⑥性能得到改善。
- 网桥的缺点:①增加时延:②MAC 子层没有流量控制功能(流址控制需要用到编号机制，编号机制的实现在LLC 子层) : ③不同MAC 子层的网段桥接在一起时，帧格式的转换: ④网桥只适合于用户数不多和通信量不太大的局域网，否则有时还会因传播过多的广播信息而产生网络拥塞，这就是所谓的广播风暴。
- 网桥必须具有路径选择的功能，当接收到帧后，要决定正确的路径，将该帧转送到相应的目的局域网站点。根据路径选择算法的不同，可将网桥分为透明网桥和源路由网桥。

#### 6.3，局域网交换机及其工作原理

1. 局域网交换机

   - 桥接器的主要限制是在任一时刻通常只能执行一个帧的转发操作，于是就出现了局域网交换机，又称以太网交换机.从本质上说，以太网交换机就是一个多端口的网桥，工作在数据链路层。交换机能经济地将网络分成小的冲突域，为每个工作站提供更高的带宽。
   - 以太网交换机对工作站是透明的，这样管理开销低廉，简化了网络结点的增加、移动和网络变化的操作。利用以太网交换机还可以很方便地实现虚拟局域网( Virtual LAN, VLAN) ，VLAN不仅可以隔离冲突域，也可以隔离广播域。

2. 原理

   以太网交换机的原理是， 它检测从以太端口来的数据帧的源和目的地的MAC ( 介质访问层〉地址，然后与系统内部的动态查找表进行比较，若数据帧的MAC 地址不在查找表中，则将该地址加入查找表中，并将数据帧发送给相应的目的端口。

3. 特点

   - 以太网交换机的特点如下:
     1)以太网交换机的每个端口都直接与单个主机相连(普通网桥的端口往往是连接到以太网的一个网段)，并且一般都工作在全双工方式.
     2) 以太网交换机能同时连通许多对的端口，使每一对相互通信的主机都能像独占通信媒体那样，无碰撞地传输数据。
     3) 以太网交换机也是一种即插即用设备(和透明网桥一样)，其内部的帧的转发表也是通过自学习算法自动地逐渐建立起来的。

     4)以太网交换机由于使用了专用的交换结构芯片，其交换速率较高.
     5) 以太网交换机独占传输媒体的带宽.

   - 对于普通10Mb危的共享式以太网，若共有N 个用户，则每个用户占有的平均带宽只有总带宽( 10Mb/s ) 的N 分之一。在使用以太网交换机时，虽然在每个端口到主机的带宽还是10Mb危，但由于一个用户在通信时是独占而不是和其他网络用户共享传输媒体的带宽，因此对于拥有N 对端口的交换机的总容量为N>< 10Mb/so 这正是交换机的最大优点.以太网交换机一般都具有多种速率的端口，例如，可以具有10Mb/s ， IOOMb/s 和1 Gb/s 的端口的各种组合， 这就大大方便了各种不同情况的用户.

4. 两种交换模式

   - 目前，以太网交换机主要采用两种交换模式，即直通式和存储转发式。
     1. 直通式交换机只检查帧的目的地址，这使得帧在接收后几乎能马上就被传出去。这种方式速度很快， 但缺乏智能性和安全性，也无法支持具有不同速恕的端口的交换.
     2.  存储转发式交换机先将接收到的帧缓存到高速缓存器中，并检查数据是否正确，确认无误后通过查找表转换成输出端口将该帧发迭出去. 如果发现帧有错，就将其丢弃。存储转发式的优点是可靠性高并能支持不同速度端口间的转换，缺点是延迟较大.

## 三，网络层

### 3.1，网络层的功能

网络层要完成的功能之一就是寻找一种中间设备实现各种异构网络的互连，以构成更大的网络系统，根据不同层次，划分为不同的中间系统：

- 物理层：中继器，集线器（Hub)
- 数据链路层：网桥，交换机（switch）
- 网络层：交换机（route）
- 网络层以上：网关

Note:采用物理层以及数据链路层设备，仅仅是把一个网络从范围上面扩大了，从网络方面看，他们仍属于一个网络，而采用网络层设备，是把许多不同的网络（比如以太网，广域网）相互连接起来。在TCP/IP网络体系结构里，网络层采用的是ip协议，但相互连接的网络可以是异构的，即使用不同的网络层协议，因此，用路由器把不同的网络相互连接起来，从网络层来看就好像是一个虚拟的ip网络，网络上的主机在通信时就好像在一个网络上通信一样，看不见网络具体的异构细节。

### 3.2，拥塞控制与路由转发

- 路由器主要完成两个功能，一是路由选择，二是分组转发，路由选择即根据当前的网络构造出路由表，同时经常的和其他路由器之间相互交换路由表来维护路由信息，而分组转发是路由器根据路由表得出来转发表，每个分组在根据转发表查询从相应的接口转发出去。
- 拥塞控制：在子网中通常会出现网络中的分组过多而发生拥塞现象，判断网络是否进入拥塞状态的方法是观察网络的吞吐量，与网络负载之间的关系，如果网络的吞吐量随着网络的负载增大而减小，那么网络就可能进入了拥塞状态，当网络吞吐量下降到0时，网络就进入了死锁状态。为了避免网络发生拥塞，要进行拥塞控制，主要是如何获取网络中拥塞的信息，从而利用这些信息对网络进行控制，避免出现死锁状态发生，注意拥塞控制和流量控制的区别，拥塞控制是一个全局性问题，是控制整个网络上分组的量，拥塞控制涉及各个主机，路由等，如果仅仅单一的增加某一个资源不能解决网络拥塞问题，而流量控制解决的是点到点之间流量问题，可以通过控制发送方发送数据的速率来达到流量控制的目的，
- 拥塞的控制方法：
  - 开环控制是一种静态的预防方法。
  - 闭环控制：是一种动态的控制方法。

### 3.3，ipv4分组NAT地址转换

1. 一个ipv4分组由数据和首部组成，首部前一部分固定20B，首部固定部分后面是一些可选字段，长度可以改变，用来提供错误检查和安全机制。

!["ipv4格式"的图片搜索结果](https://img-blog.csdnimg.cn/20181102185305353.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3JpY2hlbnl1bnFp,size_16,color_FFFFFF,t_70)

- ipv4首部的长度表示固定长度+可选字段长度，最小20B。
- 标示：在把一个数据报分片的时候用来标示每一个分片，使得在接收端可以重组。
- 首部校验和：只检验首部，而不检验数据部分。
- 首部长度，总长度，片偏移的基本单位是4B,1B,8B。

2. ip数据报的分片
   - 在数据链路层所能够承受的最大数据部分称之为最大传送单元MTU，应为ip数据报被封装在帧的数据部分，因此ip数据报受MTU的限制当ip数据报长度超过mtu时，就需要进行分片。
   - note:分组在一个网络中转发需要用MAC地址进行转发，因此这里要用到ARP地址转换协议，并且在一个网络中转发分组的时候MAC地址一直在变化，ip地址只在网络之间进行寻址。
3. 常用三类ip地址的范围

| 网络类别 |                        | 第一个可用网络号 | 最后一个可用网络号 | 每个网络中最大主机数 |
| -------- | ---------------------- | ---------------- | ------------------ | -------------------- |
| A        | 2^7^-2                 | 1                | 126                | 2^24^-2              |
| B        | 2^14^-1，128.0不指派   | 128.1            | 191.255            | 2^16^-2              |
| C        | 2^21^-1，192.0.0不指派 | 192.0.1          | 223.255.255        | 2^8^-2               |

==特殊地址：==

- 主机号全0标示本网络本身，主机号全1标示本网络的广播地址，又叫做直接广播地址。
- 127.0.0.0标示环回测试，标示任何主机自己本身，此主机发出的分组永远不能出现在网络上。
- 32位全为0表示本网络上的本主机。
- 32位全为1表示网络的广播地址，路由器有隔离广播域的功能，因此255.255.255.255等效于本网络的广播地址。
- 网络号全0标示保留地址，意思是本网络。
- 127网络地址作为环回测试。

ip地址的特点：

1. ip地址是一种分等级的结构，由主机号和网络号组成，其中网络号由专门的管理机构分配，主机号由单位自行分配。路由器仅仅根据目的主机的网络号进行转发分组，减小了路由表所占的空间。
2. ip地址标示一台主机和一条链路的接口，当一台主机同时连接到两个网络上的时候，该主机必须有两个ip地址，每个ip地址的网络号必须和所在的网络号相同，并且两个ip地址的网络号不相同，网络上的路由器至少两个ip地址。
3. 用转发器或者网桥连接起来的网络仍然是一个网络，同一个广播域，因此一个网络中所有主机的网络号必然相同，但是主机号不一定相同。
4. 在网络中，所有分配到ip地址的主机是平等的。

网络地址转换（NAT)

- 网络地址转换是指将专网网络地址转换为公共网络地址，从而对外隐藏了内部的ip地址，它使得整个专用网只需要一个全球的ip地址就可以将专用网连接到互联网上，专用网本地的ip地址是可重用的，因此节省了ip地址的消耗。
- 全球的私有ip地址只用于局域网，不用于广域网，因此必须利用NAT转换机制把私有的ip地址转换为共有的唯一全球ip地址，全球私有ip地址：
  - 一个A类网段：10.0.0.0----10.255.255.255
  - 16个B类网段：172.16.0.0----172.31.255.255
  - 256个C类网段：192.168.0.0----192.168.255.255
- 在因特网中的所有路由器中，对目的地址是私有地址的数据报一律不进行转发，这种采用私有ip地址的网络称为专用互联网或者本地互联网，
- NAT路由器至少有一个全球的ip地址，路由器维护一个转发表，路由表中存放{本地ip地址：端口}到{全球ip地址：端口}的映射，可以让多个私有ip地址映射到一个全球唯一ip地址。
- 普通路由器在转发ip数据报的时候，不改变其源ip地址和目的ip地址，而NAT路由器在转发分组的时候要更换其源ip地址和目的ip地址，普通路由器工作在网络层，而NAT路由器还要使用传输层的端口号。

### 3.4，子网划分和子网掩码，CIDR

- 两级的ip地址利用率很低，给每一个物理网络分配一个网络号会使路由表变大使得网络的性能变坏。
- 子网划分的思路：
  - 子网划分属于一个单位内部的事情，单位对外部仍表现为一个网络。
  - 从主机号中借出几个比特位作为子网号，从而ip地址变成了三级结构{<网络号><子网号><主机号>}
  - 凡是从其他主机发送给本单位的数据报，先按照网络号在网络中进行分组转发，最后找到目的网络后，目的网络路由器按照子网号在本网络中进行转发，最后交到目的主机。
- 地址掩码
  - 为了告诉路由器A,B,C类网络进行了子网划分，使用子网掩码来表达对源网络中主机号的借位。
  - 地址掩码只有一串1和一串0组成，其中1的个数对应于ip地址中网络号和子网号的位数，而0的个数对应于主机号的位数，ip地址只需要和子网掩码逐位相与运算就可得到相应子网的网络地址。
  - 一台主机在设置ip地址的同时，必须设置子网掩码。
  - 同属于一个子网的所有主机以及路由器端口必须设置相同的子网掩码。
  - 路由器的路由表中所包含的内容主要有{网络地址，子网掩码，下一条地址}。
- 无分类域间路由选择（CIDR）
  - 特点：
    - 消除了传统的A,B,C类地址划分和子网掩码的概念，可以更有效的分配ipv4的地址空间，CIDR使用网络前缀的概念代替了子网的概念，因此ip地址变为两级结构{网络前缀，主机号}，使用斜线记法。
    - 将网络前缀相同的连续ip地址组成CIDR地址块，一个CIDR地址块可以表示很多ip地址，这种地址聚合称为路由聚合或者称为构造超网。
    - CIDR地址块中的地址数一定是2的整数次幂，实际可以指定的地址数是2^n^-2,n代表主机号的位数，主机号全0代表网络号，主机号全1代表广播地址。
    - 最长前缀匹配原则，使用CIDR时路由表中的每一个项目由网络前缀和下一条地址组成，在查找路由表时可能有不止一个的匹配结果，因此要选择最长匹配的网络号，应为网络号越长，对应的地址位数就越少，搜索地址范围就越小。

### 3.5，ARP,DHCP,ICMP协议

-  地址解析协议ARP

  - ip地址是网络层使用的地址，MAC地址是数据链路层和物理层使用的地址，Ip地址放在ip数据报的首部，而ip数据报作为数据部分被封装在了数据链路层的帧的数据部分，MAC地址放在mac帧的首部，数据链路层看不到封装在帧中的ip地址，由于路由器具有隔离广播域的功能，因此ip网络中无法通过MAC地址去完成分组转发的寻址功能，必须运用ip地址在网络层完成寻址，所以要用到ARP地址转换协议，把硬件地址转换为相应的ip地址完成寻址。
  - 网络上的每一台主机都要维护一个ARP高速缓存，用来存放本局域网上所有主机和路由器ip地址到MAC地址的映射，称为ARP表，ARP协议工作在网络层。
  - ARP协议用于解决同一个局域网上主机或者路由器ip地址到硬件地址的映射问题，如果所要找的主机和路由器和源主机不在同一个局域网上，那么就通过找到局域网上的一台路由器，然后把分组准发给路由器，让路由器把分组转发给下一个网络，有下一个网络来完成寻址问题。
  - 从ip地址到硬件地址的映射是自动进行的。

- 动态主机配置协议（DHCP）

  - 动态主机配置协议常常用来给主机动态的分配ip地址，他提供即插即用联网的机制，这种机制允许一台主机加入一个新的网络是自动的获取ip地址，而不用动手进行配置，DHCP是应用层协议，是基于UDP的。

    - 工作原理：

      使用客户机服务器模式，需要ip地址的主机在启动时DHCP服务器广播发送发现报文，该主机就成为了DHCP服务器的客户，本网络上的所有主机都会受到此报文，但是只有DHCP服务器响应此报文，服务器查询ip地址池中是否有该计算机的配置，若果有就返回信息，没有就分配ip地址。

  - DHCP服务器分配给主机的ip地址是临时的，因此客户机只有在有限时间内使用该ip地址。

- 网际控制报文协议（ICMP）

  - 为了让ip数据报提高交付成功的机会，在网络层使用了网际控制报文协议来报告出差错的情况，ICMP报文作为ip数据报的数据部分。加上数据报的首部，组成ip数据报发送，ICMP是网络层协议。
  - ICMP有两种报文：ICMP差错报告报文，ICMP询问报文。
    - ICMP差错报文用于目标主机或者目标主机路径上的路由器向源主机报告差错的情况
      - 终点不可达：不能按时交付数据。
      - 源点抑制：发生拥塞。
      - 时间超时：终点收到TTL为0的数据报。
      - 参数问题：数据报首部中的字段值不正确。
      - 改变路由：路由器把改变的路由发送给源主机。
    - 不发送ICMP差错报文的情况
      - 对ICMP差错报文不在发送ICMP差错报告报文。
      - 对第一个分片的数据报片的所有后续报片都不在发送ICMP差错报文。
      - 对具有组播地址的数据报不发送ICMP差错报告报文。
      - 对具有特殊地址的数据报不发送ICMP差错报告报文。
    - ICMP询问报文有四种类型
      - 回送请求和回答报文
      - 时间戳请求和回答报文
      - 掩码地址请求和回答报文
      - 路由器询问和通告报文
    - ICMP报文最直接的应用是ping操作，使用了ICMP回送请求和回答报文，ping指令工作在应用层，他直接使用网络层的ICMP，而未使用应用层的tcp和udp。

### 3.6，ipv6

- ipv6的主要特点
  - 更大的地址空间，从32位增大到128位，
  - 扩展的地址层次结构。
  - 灵活的首部格式。
  - 改进的选项。
  - 允许协议继续扩充。
  - 支持自动配置。
  - 支持资源的预分配。
  - ipv6只允许在源点进行分片，不允许在中间经过的路由出分片。
  - ipv6首部必须是8B的整数倍，ipv4是4B的整数倍。
  - 身份验证和保密功能是ipv6的关键特征。
- ipv6的地址
  - ipv6的目的地址可以是一下三种类型之一。
    - 单播
    - 多播：一点对多点的通信。
    - 任播：任播的目的站是一组计算机，但是数据在交付时只交给其中的一台计算机。
  - ippv6向ipv4的过度
    - 双协议栈法：在主机中配置两个协议栈。
    - 隧道技术法，将ipv6数据报封装在iPv4数据报中传输。

### 3.7，路由算法

1. 动态路由算法（自适应路由算法），指路由器之间相互交换信息，然后按照一定的算法得出来的路由表，这些路由信息在一定时间内会不断的更新，从而适合网络的动态变化。

2. 静态路由算法（非自适应路由算法）：通过网络管理员手工进行路由信息的配置，当网络的拓扑结构发生变化时，网络管理员手工配置路由表的信息，适合小型网络。

   - 距离-向量路由算法：所有节点定期的将他们的整个路由表选择传送给所有与之直接相连的相邻节点，这种选择路由包含：

     - 每一条路径的目的地
     - 路径的代价
     - 相邻路由器所交换的是全部路由信息。

   - 链路状态路由算法：要求每个参与该算法的节点都具有完全的网络拓扑信息，他们执行两个任务：主动测试所有临接节点的路由状态，定期的将链路状态传播给所有其他的节点

     链路状态路由算法的主要特征：

     - 向本自治系统中所有的路由器发送信息，使用洪泛法，即路由器通过所有端口向所有节点发送路由信息，而每个相邻的路由器又将此信息发往其相邻的路由器。
     - 只有当链路状态发生变化时，路由器才向所有路由器发送消息。
     - 发送的消息是与路由器相邻的所有路由器的链路状态，但这只是路由器所知道的部分信息，链路装态是指本路由器与那些路由器相连以及相邻链路的状态。

   - 两种算法的比较：

     - 在距离路由向量算法中，每一个节点仅仅与他的直接相邻节点交换信息，他为他的相邻路由器提供从自己到所有其他节点的最低费用，在链路状态路由算法中，每个节点通过广播方式与其他的节点交换信息，但是仅仅告诉他们与直接相连的链路的费用，但是距离向量路由算法中会遇到环路等问题。

   - 层次路由

     - 因特网将整个网络划分成许多小的自制系统，（每一个自制系统包含许多小的局域网），每一个自制系统有权决定本自制系统内部采取什么协议，如果两个自制系统内部主机想要进行通信，就必须屏蔽掉这种差异，所以路由协议被划分成两大类。
       - 自制系统内部的协议：内部网关协议(IGP)，也叫作域内路由选择协议。
       - 自制系统之间使用的协议，外部网关协议(EGP)，也叫作域间路由选择协议，
     - 使用层次路由时候，ospf将一个自制系统划分成多个域，每个路由器都知道在本区域内部如何把分组路由到目的地的细节，但是不用知道其他区域的内部结构。

3. 内部路由选择协议（RIp和OSPF)

   1. RIP协议的特点（RIP是应用层协议，使用udp传输数据rip选择的路径比一定时间最短，一定是跳数最少）
      1. 仅仅和相邻的路由器交换信息。
      2. 路由器交换的信息是当前路由器所知道的全部信息，即自己的路由表。
      3. 按照固定的时间间隔交换路由信息。
      4. 通过RIP收敛以后，每一个路由器到每一个目标网络的路由都是距离最短的（即跳数最少）.
   2. RIP的缺点
      1. RIP限制了网络的规模，他可以使用的最大规模为15跳。
      2. 路由器中交换的是路由器中整个的路由表，因此网络规模越大，开销就越大。
      3. 网络出现故障时，会出现慢收敛的现象，（即需要很长时间需要将信息传输到所有的路由器），也叫作坏消息传输的慢，使得网络的收敛时间过长。

4. 开放最短路径优先（OSPF）协议

   1. 特点：
      1. OSPF向本自制系统中所有的路由器发送消息，这里使用的是洪泛法，而rip仅仅向相邻的路由器发送消息。
      2. 发送的消息是与本路由器相邻的所有路由器的链路状态，但这只是路由器所知道的部分信息，“链路状态”说明本路由器和那些路由器相邻以及该链路的度量代价，而在rip中，所发送的信息是本路由器所知道的全部信息。
      3. 只有当链路状态发生变化时路由器才使用洪泛法向所有路由器发送信息，并且更新过程很慢，不会出现坏消息发送的慢的情况。但是这里交换信息仅仅是发送变化部分的信息。
      4. OSPF是网络层协议，直接使用ip发送数据报传输，而RIP是应用层协议，使用传输层的UDP.
   2. OSPF的工作原理：
      1. 由于各个路由器之间频繁的交换路由信息，因此所有的路由器都建立了一个链路状态数据库，这个数据库实际上是全网的拓扑结构，在全网内是唯一的，然后根据全网络的拓扑结构，用地杰斯特拉算法计算从自己到各个路由器的最佳路径，从而构造路由表，使用算法构造的路由表，存储的不是完整的路径，而是下一跳地址，而OSPF还把一个自制系统划分成许多的域，使用洪泛法交换信息时候，每个路由器交换的链路状态信息仅仅局限于每一个区域内部，而不是整个自制系统，减少了整个网络的通信量，在一个区域内部的路由器仅仅知道本区域网络的拓扑结构，。

5. 外部网关协议（BGP)

   - 外部网关协议只能力求寻找一条能够到达目的网络比较好的路径，而不是寻找一条最佳路径，BGP采用路径向量路由选择协议，BGP是应用层协议，是基于TCP的协议。

   1. BGP的工作原理
      - 每一个自制系统至少选择一个路由器作为该系统的“BGP发言人”，一个系统的bgp发言人和其他系统的发言人交换信息，就是要先建立tcp连接，然后再连接之上交换BGP报文进行会话，当所有发言人都相互交换网络的可达性信息之后，各个发言人可以找到到达各个自制系统的较好的路由。每一个BGP发言人除了运行外部网关协议，还要运行本自制系统内部的协议。
   2. BGP的特点
      1. BGP交换路由的信息的节点数量级是自制系统的数量级，这比自制系统中的网络数少很多。
      2. 每一个自制系统中的发言人很少，这样自制系统之间的路由选择协议不是很复杂。
      3. BGP协议支持CIDR。

   

| 协议     | RIP                      | OSPF                                 | BGP                                    |
| -------- | ------------------------ | ------------------------------------ | -------------------------------------- |
| 类型     | 内部                     | 内部                                 | 外部                                   |
| 路由算法 | 距离向量                 | 链路状态                             | 距离向量                               |
| 传递协议 | UDP                      | IP                                   | TCP                                    |
| 路径选择 | 跳数最少                 | 代价最低                             | 较好，非最佳                           |
| 交换节点 | 和本节点的相邻节点路由器 | 网络中的所有路由器                   | 和本节点相邻路由器                     |
| 交换内容 | 当前路由器的路由表       | 与本路由器相邻的所有路由器的链路状态 | 首次：整个路由表，非首次：有变化的部分 |

### 3.8，ip组播





## 四，传输层

### 4.1，传输层的功能

- 从通信和信息处理的角度看，传输层向他上面的应用层提供通信服务，它属于面向通信部分的最高层，同时也是用户功能中的最底层，传输层位于网络层之上，他为运行在不同主机上面的进程提供了端到端的逻辑通信，而网络层提供主机之间的逻辑通信即使网络层的传输不可靠，传输层也可以保证可靠传输。
- 传输层的功能
  - 传输层提供应用进程之间的逻辑通信（即端到端的通信），而网络层提供主机之间的通信。
  - 复用和分用的功能。复用是指发送方不同的应用进程都可以使用同一个传输层协议传输数据，分用是指接收方的传输层在剥去报文的首部后能把这些数据交付到目的地的应用进程。
  - 传输层还要对接收到的报文进行差错检验，（首部和数据部分），而网络层只检验首部，
  - 提供两种不同的传输层协议，面向连接的TCP和无连接的UDP。而在网络层只能提供面向连接的（虚电路服务）的服务或者数据报服务（无连接）。

### 4.2，传输层的寻址和端口

1. 端口：端口可以让应用程序将其数据通过端口交付给传输层，以及可以让传输层知道应将其中的报文段交付给应用层的哪一个进程，端口是传输层的服务访问点，数据链路层的服务访问点是MAC地址，网络层的服务访问点是ip。
2. 端口号
   - 服务端使用的端口号：
     - 熟知端口号
     - 登记端口号
   - 客户端使用的端口号：49152-65535
3. 套接字
   - 在网络中通过不同ip来标示一台主机，通过端口号来标示进程，而套接字=（主机ip地址：端口号）可以用来标示一台主机上的一个进程，

### 4.3，无连接服务与面向连接服务

1. 面向连接服务是指在通信之前双方必须先建立连接，在通信过程中，整个连接的情况一直被实时的监控和管理，通信结束后释放连接。
2. 无连接服务是指双方在通信时不需要建立连接，直接将数据发送到网络中，尽最大努力交付。

- TCP/IP协议组在网络层之上提供了两种服务，即一种是面向连接的传输控制协议tcp,他向应用层提供一条全双工的逻辑信道。另一种是无连接的用户数据报协议UDP。传输层向上提供一条不可靠的逻辑通信。 

### 4.4，UDP协议

1. UDP协议的特点：
   1. UDP协议无需建立连接。
   2. 分组首部开销小仅有8B开销，而TCP有20B的开销。
   3. 应用层可以更好的控制要发送的数据的发送时间，UDP没有拥塞控制，
   4. UDP尽最大努力交付，即不保证可靠交付。但这并不意味着应用对数据的要求是不可靠的。
   5. UDP是面向报文的，发送方UDP对应用层叫下来的报文，在添加首部就交给ip层，既不拆分，也不进行合并，而是保留这些报文的边界。
2. UDP首部格式组成（一共8B）：
   1. 源端口2个字节。
   2. 目的端口一共2个字节。
   3. UDP的长度占两个字节。
   4. UDP检验和占两个字节。
3. UDP校验
   1. 校验时，如果UDP数据部分长度不是偶数个字节，需要填入一个全0字节，但是此字节和伪首部是一样的，不发送。
   2. 如果UDP校验检验处UDP数据报是错误的，那么可以丢弃，也可以交付给上层，但是需要附上错误的报告。
   3. 通过伪首部，不仅可以检查源端口号，目的端口号，和UDP数据部分，还可以检查数据报的源IP地址和目的IP地址。 

### 4.5，`TCP`协议

1. `TCP`协议的特点：

   1. `TCP`是面向连接的传输层协议。
   2. 每一条`TCP`连接只能有两个端点，每一条`TCP`连接只能是点对点的。
   3. `TCP`协议提供可靠交付服务，保证传输的数据无差错，不重复，无丢失。
   4. `TCP`提供全双工的通信。
   5. `TCP`是面向字节流的。
   6. `tcp`报文段既可以运载数据，也可以用来建立连接，释放连接和应答。

2. `TCP`报文段的字节格式：（固定首部`20B`，长度一般是`4B`的整数倍）

   ![](../img/network/tcp.jpg)

   1. 序号字段：各占4`B`,`TCP`面向字节流，所以`TCP`传输的每一个字节都编上序号。序号字段的值是本报文段所发送数据的第一个字节的序号。
   2. 确认序号段：占4`B`，是期望收到对方下一个报文段数据的第一个字节。
   3. 数据偏移：占4`B`，标示首部长度，因为`Tcp`首部固定字段后面有选项字段，指出`TCP`数据字段距离`TCP`报文段起始处有多远。数据偏移的单位是32位，以4`B`为计算单位，最大长度达到60`B`。
   4. 紧急指针`URL`:当`URG`为1的时候，表名紧急指针字段有效，告诉系统报文段中有紧急数据，相当于高优先级的数据。但是URG要和紧急指针配合使用，即数据从第一个字节到紧急指针所指的字节数为紧急数据。
   5. 确认位：只有当ACK=1时确认号字段才有效，当ACK确认序号为0的时候，确认号无效，TCP规定在连接建立后ACK必须为1,。
   6. 推送位PSH：当TCP接收到psh=1的报文的时候，就尽快的交付给上面的应用层的进程，而不用等到整个缓存满后再交给上层进程。
   7. 复位为RST：RST=1的时候表名TCP连接中出现了严重的差错，必须释放连接，然后在重新建立连接。
   8. 同步位（SYN）:同步为标示这是一个连接请求或者连接接收报文。当ACK=0,SYN=1的时候，表名这是一个连接请求的报文，如果对方同意建立连接，就把ACK设置为1进行回应，即SYN表示这是一个连接请求或者接受的报文。
   9. 窗口字段：占2B，他指出现在允许发送端发送的数据量，接收方的数据缓存空间时有限的，顾窗口字段作为接收方让发送方允许发送数据量的依据。
   10. 校验和：占2B，校验和检验的部分包括首部和数据部分，在计算校验和的时候，和UDP一样，需要在TCP报文的首部添加12B的伪首部，
   11. 紧急指针位：栈16位，指出本报文段中数据一共有多少的字节，
   12. 选项字段，长度可以改变，TCP最初只规定了一种选项，即最大报文段长度MSS,MSS是TCP报文段中的数据字段的最大长度。
   13. 填充字段：这个是为了使整个首部长度为4B的整数倍。
   14. 终止位：FIN=1表名此报文的发送方的数据已经发送完毕，并且要求释放连接。
   15. 源端口和目的端口字段：各占2`B`，端口是传输层和应用层的服务接口，运输层的

3. TCP连接管理：

   - TCP是面向连接的协议，因此每个TCP连接有三个阶段：连接建立，数据传送，连接释放

   1. TCP连接建立过程：
      1. 客户机的TCP首先向服务器的TCP发送一个连接请求报文，这个特殊的报文中不含数据字段，其中首部的SYN=1,客户机会随机选择一个需要seq=x,（连接请求不需要携带数据，但是消耗序号）
      2. 服务器TCP连接收到请求后，如果允许建立连接，就向客户机发送确认，在确认报文中ACK=1,SYN=1,确认号字段的值为x+1,并且服务器也随机产生一个序号seq=y，（确认报文不携带数据，但是消耗序号）
      3. 当客户机收到确认报文后，还要向服务器给予确认，确认报文中ACK=1,序号字段为seq=x+1,确认号字段ack=y+1,该报文可以携带数据，如果不携带数据就不消耗序号。
      4. 服务器的资源是在完成第二次握手时分配的，而客户机资源是在完成第三次握手时分配的，这就使得服务器免收SYN洪泛攻击。
   2. TCP连接的释放：
      1. 客户机关闭连接时，向其TCP发送一个连接释放请求，并且停止发送数据，主动关闭TCP连接，FIN=1，seq=u,（u是前面已经传送数据的最后一个字节的序号+1），FIN报文不携带数据，但是需要消耗一个数据。
      2. 服务器收到连接释放报文段后发出确认，确认号ack=u+1,而这个确认报文段自己的序号是v，（v等于前面传送数据最后一个字节的序号+1），此时这条全双工的链路就处于半关闭状态，即客户机不可以向服务器发送数据，但是服务器可以向客户端发送数据。
      3. 如果服务器没有数据发送，就发出FIN=1的报文，请求释放连接。
      4. 客户机收到连接释放报文段后，必须发出确认，在确认报文段中，ACK=1,确认序号ack=w+1,确认报文段自己的序号seq=U+1,但是此时TCP连接还没有释放，必须经过时间计时器2MSL之后才进入关闭状态。
   3. 建立和关闭的总结
      - 建立连接,三次挥手
        ~~~ java
        1. SYN=1,seq=x
        2. SYN=1,ACK=1,seq=y,ack=x+1
        3. ACK=1,seq=x+1,ack=y+1
        ~~~

      - 释放连接，四次握手
        ~~~ java
        1. FIN=1,seq=u
        2. ACK=1,seq=v,ack=u+1
        3. FIN=1,ACK=1,seq=w,ack=u+1
        4. ACK=1,seq=u+1,ack=w+1
        ~~~
   4. TCP可靠传输机制

   - TCP的任务是在IP层不可靠的传输层之上建立一条可靠的数据传输服务。TCP使用校验，序号，确认和重传机制来达到目的，其中校验机制与UDP校验一样。
     - 序号
       - ·TCP连接传送的数据流中的每一个字节都编上了序号，序号字段值是指本报文段发送数据的第一个字节的序号
     - 确认：
       - TCP首部的确认号是期望收到对方的下一个报文段的数据的第一个字节的序号，发送方的缓存会持续存储哪些已经发送但是未收到确认的报文段，以便在需要的时候重传，TCP默认使用累积确认的方式，即TCP只确认数据流中至第一个丢失字节位置的字节。
     - 重传：
       - 两种事件会导致重传：超时和冗余ACK
         - 超时：TCP每发送一个报文段，就对这个报文段设置一个计时器，计时器时间到但是未收到确认就重传数据报。
         - 冗余ACK：标示发送方多次接收到了来自接收方的确认帧，即冗余确认机制，遇到这种情况，发送方通常开始快速重传机制。

   5. 流量控制：

      TCP提供流量控制来消除发送方使接收方缓存区域发生溢出的可能，因此可以说流量控制是一个速度匹配服务。TCP的流量控制也是基于滑动窗口协议的。

      - 流量控制是一个速度匹配的服务，匹配发送方的发送速率与接收方的接收速率，防止发送方发送数据过快而使接收方来不及接收数据发生丢包现象。

      - 在接收方，通常维护一个接收窗口rwnd来动态调整TCP报文段中首部的窗口值，来限制发送方向网络中注入报文的速率。同时，发送方根据网络的拥塞窗口来估计发送窗口值，也叫作拥塞窗口cwnd，通常拥塞窗口=min{cwnd,rwnd}.

      - 传输层流量控制和数据链路层流量控制的区别：传输层是端到端的流量控制，数据链路层定义中间两个节点之间的流量控制，并且数据链路层的滑动窗口大小不可以动态的变化传输层窗口可以动态变化。

        ![](../img/network/流量控制.png)

   6. TCP拥塞控制

      1. 所谓拥塞控制是防止过多的数据包注入到网络，以使网络中的路由器或者链路过载，当出现拥塞时，端点之间并不了解拥塞发生的细节问题，对于通信的端点来说，往往表现为端到端的传输时延增大，拥塞和流量控制的共同点是都是通过控制发送方发送数据的速率来控制效果。但是两者也有区别，拥塞控制是让网络可以承受现有的网络负荷，是一个全局性的问题，涉及到所有的主机，路由器，链路，但是，流量控制往往是指点对点的通信量的控制，即接收端控制发送端，接收端所要做的就是抑制发送端发送数据的速率，使得接收端来得及接收。通常用四种算法来对拥塞进行控制：慢开始，拥塞避免，快重传，快恢复。

      2. 发送方在确定发送数据报文段的速率的时候，要根据接收方接收能力，又要从全局考虑使得网络不要过度拥塞，因此TCP往往要维护两个窗口。

         1. 接收窗口（rwnd）:接收窗口根据目前接收缓存的大小所许诺的最新窗口值，反应接收窗口的容量大小，由接收方根据其放在TCP报文段的首部接收窗口大小中传输给发送方。

         2. 拥塞窗口（cwnd):发送方根据自己估算的网络拥塞成都而设置的窗口值，反映了当前网络的拥塞程度。只要网络发生了拥塞，拥塞窗口就会减少一点。

         3. 发送窗口的上限取决于接收窗口和拥塞窗口中较小的哪一个，即：

            发送窗口=min{接收窗口，拥塞窗口}

      3. 下面对拥塞窗口的细节进行探讨。

         1. 慢开始算法：

            - 当TCP刚刚进行连接并且进行发送TCP报文的时候，先让拥塞窗口值的大小为1，即一个最大报文段的长度MSS，每收到对一个新的报文段的确认后，九江拥塞窗口增加1即增大一个MSS,用这样的方法逐渐增大拥塞窗口，以控制发送到网络的数据包。
            - 使用慢开始算法，每经过一个传输轮次（即一个RTT），拥塞窗口的值就会增大一倍，即拥塞窗口的大小呈指数型增长，这样，当慢开始算法一直把拥塞窗口的值增大到一个慢开始门限值sstresh时，就开始执行拥塞避免算法。

         2. 拥塞避免算法

            - 拥塞避免的算法如下,发送端的拥塞窗口每经过一个RTT就增加一个MSS大小，而不是加倍，使拥塞窗口按照线性缓慢增长(**即加法增大**)，而当出现一次网络超时的时候（网络拥塞），就另慢开始门限ssthresh的值等于当前拥塞窗口值的一半（**即乘法减小算法**）。

            - 归纳：

              ~~~ java
              cwnd<ssthresh//使用慢开始算法
              cwnd>ssthresh//改用拥塞避免算法
              cwnd=ssthresh//既可以使用慢开始算法，又可以使用拥塞避免算法
              ~~~

         3. 网络拥塞的处理：

            - 网络出现拥塞的时候，无论是在慢开始阶段，还是在拥塞避免阶段，只要发送方检测到超时的发生，（没有按时收到确认，重传计时器超时），就把慢开始门限的值ssthresh的值设置为出现拥塞时拥塞窗口值的一半，但是不可以小于2，然后把拥塞窗口的值设置为1，执行慢开始算法，这样做的目的是迅速减少发送到网络中的分组数目，使得发生拥塞的路由器有足够的时间把队列中挤压的分组处理完。

            - 但是拥塞避免也不能完全避免拥塞，拥塞避免是指在拥塞避免算法中把拥塞窗口的大小控制为按照线性增长。

              ![](../img/network/慢开始算法.jpg)

              - 初始时：拥塞窗口的值为1，慢开始门限设置为16，慢开始阶段，拥塞窗口的初始值为1每次经过一个传输轮次，拥塞窗口的值就加倍，所以在慢开始算法阶段，拥塞窗口的大小呈指数型增长。
              - d昂拥塞窗口的值增长到慢开始门限的值16的时候，发生了拥塞，就改用为拥塞避免算法，拥塞窗口的大小呈线性增长。
              - 当拥塞窗口继续增长到24的时候，网络发生拥塞，此时让慢开始门限的值为此时的拥塞窗口值大小的一半，即12，在让拥塞窗口的大小为1，并且开始执行慢开始算法，当拥塞窗口再次达到12的时候，再次改为使用拥塞避免算法。
              - 注意在慢开始〈指数级增长〉阶段， 当2cwnd >ssthresh时，则下一个RTT的cwnd 等于ssthresh，而不是等于2cwnd， 即cwnd 不能跃过ssthresh值，在第16 个轮次时cwnd = 8，ssthresh= 12，在第17 个轮次时cwnd = 12.，而不等于16.
              - 在慢开始和拥塞避免算法中使用了"乘法减小"和"加法增大"方法。"乘法减小"是指不论在慢开始阶段还是拥塞避兔阶段，只要出砚一次超时(即很可能出现了网络拥塞)，就把慢开
                始门限值ssthresh设置为当前的拥塞窗口值的一半。当网络频繁出现拥塞时， ssthresh值就下降得很快，以大大减少注入到网络中的分组数。而"加法增大" 是指执行拥塞避免算法后，当收到对所有报文段的确认后〈即经过一个RTT) ，就把拥塞窗口cwnd 增加一个MSS 大小，使拥塞窗口缓慢增大，以防止网络过早出现拥塞。

            - 快重传和快恢复
              快重传和快恢复算法是对慢开始和拥塞避免算法的改进。

              - 快重传
                在上一节TCP 可靠传输机制中， 快速重传技术使用了用冗余ACK 来检测丢包的发生。同样，冗余ACK 也用于网络拥塞的检测(丢了包当然意味着网络可能出现了拥塞).快重传并非取消重传计时器， 而是在某些情况下可更早地重传丢失的报文段。
                当发送方连续收到三个监复的ACK 报文时，直接重传对方尚未收到的报文段，而不必等待那个报文段设置的重传计时器超时。

              - 快恢复
                快恢复算法原理: 当发送端收到连续三个冗余ACK (即重复确认〉时，就执行"乘法减小"
                算法，把慢开始门限ssthresh 设置为出现拥塞时发送方cwnd 的一半.与慢开始(慢开始算法将拥塞窗口cwnd 设置为1 )不同之处是它把cwnd 的值设置为慢开始门限ssthresh 改变后的数值，然后开始执行拥塞避免算法("加法增大'，使拥塞窗口缓慢地线性增大。

              - 由于跳过了cwnd 从l 起始的慢开始过程， 所以被称为快恢复。快恢复n法的实现过程如下：

                ![](../img/network/快恢复.png)

                在流量控制中，发选方发送数据的量由接收方决定，而在拥塞控制中，发送方自己通过检测网络状况而决定。实际上，慢开始、拥挫避免算法、快蓝传和快恢挝几种算法应该趋同时应用在拥塞控制机制之中的，当发送方检测到超时的时候就采用馒开始和拥l塞避免， 当发送方接收到冗余ACK 的时候就采用快重传和快恢复。发送方发送窗口 的实际大小由流量控制和拥塞控制共同决定。因此，当题目中同时出现了接收端窗口(rwnd) 表明塞窗门(cwnd) 时，发送方实际的发送窗口大小是由rwnd 和cwnd 中较小的那一个确定的。

## 第五章，应用层

### 5.1，**网络应用模型**

#### 5.1.1，客户/服务器模型

1. 在客户/服务器(ClientJServer ，C/S) 模型中，有一个总是打开的主机称为服务器，它服务于许多来自其他称为客户机的主机请求。其工作流程是:
   1. 服务器处于接收请求的状态。
   2. 客户机发出服务请求， 并等待接收结果。
   3. 服务器收到请求后， 分析请求，进行必要的处理，得到结果并发送给客户机。
2. 客户程序必须知道服务器程序的地址，在户机上一般不需要特妹的硬件和复杂的操作系统。而服务器上运行的软件则是专门用来提供某种服务的程序，可同时处理多个远程或本地客户的要求。系统启动后即自动调用并一直不断地运行着， 被动地等待并接收来白各地客户的请求。因此，服务器程序不需要知道客户程序的地址。
   客户/服务器模型最主要的特征是: 客户是服务请求方，服务器是服务提供方.
3. 常见的使用客户/服务器模型的应用包括：Web、文件传输( FTP、远程登录和电子邮件等)
4. 客户/服务器模型的主要特点还有:
   1. 网络中各计算机的地位不平等，服务器可以通过对用户权限的限制来达到管理客户机的目的，使它们不能随意存储/删除数据，或进行其他受限的网络活动。整个网络的管理工作由少数机服务器担当，故网络管理非常集中和方便。
   2.  客户机相互之间不直接通信。例如， 在Web 应用中两个浏览器并不直接通信。可扩展性不佳。受硬件和网络带宽的限制， 服务器支持的客户机数有限。

#### 5.1.2，P2P模型

1. 在C/S 棋型中，服务器性能的好坏决定了整个系统的性能，当大量用户的请求服务时，服务器就必然成为系统的瓶颈.**P2P**的思想是整个网络中的传输内容不再被保存在一个中心服务器上，每个结点都同时具有下载、上传的功能， 其权利和义务都是大体对等的。

2. 在P2P 模型中， 各计算机没有固定的客户和服务器划分。相反， 任意一对计算机一一称为对等方( Peer ) ，且接相互通信.实际上， P2P 模型从本质上来看仍然是使用客户/服务器方式，每个结点既作为客户访问其他结点的资源，也作为服务器提供资源给其他结点访问.当前比较流行的P2P 应用如PPli ve 、Bittorrent 和电驴等。

3. 与C/S 模型相比， P2P 棋型的优点主要体现在:

   1. 减轻了服务器的计贺.压力，消除了对某个服务器的完全依赖，可以将任务分配到各个结点上， 因此大大提高了系统效率和资源利用率(例如， 播放流媒体时对服务器的压力过大， 而通过P2P 棋型， 可以利用大量的客户机来提供服务)。
   2. 多个客户机之间可以直接共享文挡。
   3. 可扩展性好， 传统服务器有响应和带宽的限制， 因此只能接受一定数量的请求。
   4. 网络健壮性强，单个结点的失效也不会影响其他部分的结点。
      P2P 模型也有缺点， 在获取服务的同时， 还要给其他结点提供服务，因此会占用较多的内存，影响整机速度.例如， 经常进行P2P 下我还会对硬盘造成较大的损伤。据某互联网调研机构统计，当前P2P 程序已经占据了五联网50%~90%的流盘，使网络变得非常拥嚣， 因此各大ISP (互联网服务提供商，如电信、网通等〉通常部对P2P 应用持反对态度。

   ![](../img/network/模型.png)



### 5.2，DNS 系统

1. 域名系统DNS (Domain Name System ) 是因特网使用的命名系统，用来把便于人们记忆的含有特定含义的主机名(如www.cskaoyan. com )转换为便于机器处理的lP 地址。
2. 从概念上看可以将DNS 分为3 个部分: 层次域名空间、域名服务器和解析器。

#### 5.2.1，层次域名空间

- 因特网采用版次树状结构的命名方法。采用这种命名方法， 任何一个连接在因特网上的主机或路由器，都有一个唯一的层次结构的名字，即域名( Domain Name). "域" ( Domain ) 是名字空间中一个可被管理的划分。域还可以划分为子域，而子域还可以继续划分为子域的子域， 这样就形成了顶级域、-一级域、二级域等。每一个域名部是由标号序列组成，而各标号之间用点(" ." )隔开。

   ![](../img/network/域名.png)

   1. 关于域名中的标号有以下几点需要注意:

      1. 标号中的英文不区分大小写。
      2. 标号中除连字符(-)外不能使用其他的标点符号.
      3. 每一个标号不超过63 个字符，多标号组成的完整域名最长不超过255 个字符。
      4. 级别最低的域名写在最左边，而级别最高的顶级域名写在最右边.

   2. 顶级域名有一下三大类：

      1. 罔家顶级棋名nTLD ，国家和某些地区的域名，如，( .cn" 表示中园， " .μs" 农示美国， ".uk"
         表示英国， ".h k" 友示中国香港特区。
      2. 通用顶级域名gTLD，常见的有".com " (公司企业)、" .net " (网绵服务机构〉、".0咆" (非
         营利性的组织〉和".gov" (美国的政府部门〉等.
      3. 基础结构域名。这种顶级域名只有一个，即arpa ，用于反向域名解析， 因此又称为反向域名。

   3. 国家顶级域名下注册的τ级域名均由该国家自行确定

      ![](../img/network/域名树.png)

#### 5.1.2，域名服务器

- 因特网的域名系统被设计成一个联机分布式的数据库系统，并采用客户/服务器模式，域名到IP 地址的解析是由运行在域名服务器上的程序完成的，一个服务器所负由管辖的范围〈或有极限的〉也称为区〈不足以"域"为根位)，各单位根据具体恬况来划分自己管辖范围的区，每在一个区中的所有结点必须是能够连通的，每个区设有相应的权限域名服务器，用来保存该区巾的所有主机的域名到IP 地址的映射.每一个域名服务器不但能够进行一些域名到lP 地址的解析，而且还必须具有连向其他域名服务器的信息.当自 己不能进行域名到ip地址的转换时，能够知道到什么地方去找别的域名服务器。
- DNS 使用了大量的域名服务器，它们以层次方式组织。没有一台域名服务器具有因特网上所有主机的映射，相反，该映射分布在所有的DNS 服务器上.采用分布式设计的DNS 系统，是一个在因特网上实现分布式数据库的精彩范例.主要有四种类砌的域名服务器.

1. 根域名服务器

   根域名服务器姓最高层次的域名服务器， 所有的根域名服务器都知道所有的顶级域名服务器的I P 地址。根域名服务器也是最重要的域名服务器，不管是哪一个本地域名服务器，若要对因特网上任何一个域名进行解析，只妥自己无法解析，就首先要求助于根域名服务器。因特网上有着13 个根域名服务器，尽管我们将这13 个根域名服务器中的每个都视为单个的服务器，但每台"服务器"实际上是冗余服务器的集群，以提供全性和可靠性。需要注意的是，根域名服务器用来管辖顶级域〈如.com) ，通常它并不直接把待查询的域名直接转换成iP 地址，而是告诉本地域名服务器下一步应可找哪一个顶级域名服务器进行奇询.

2. 顶级成名服务器

   这些域名服务器负责管理在该顶级域名服务器注册的所有二级域名，当收到DN S 查询请求时，就给出相应的回答(可能是最后的结果， 也可能是下一步应当查找的域名服务器的Ip地址〉。

3. 授权精名服务器 (权限域名服务器 )

   每一个主机都必须在授权域名服务器处登记.为了更加方便地工作， 一个主机最好至少有两个授权域名服务器。实际上， 许多域名服务器都同时充当本地域名服务器和授权域名服务器。授权域名服务器总是能够将其管辖的主机名转换为该主机的IP 地址。

4. 本地成名服务器

   本地域名服务器对域名系统非常重要，每一个因特网服务提供者I SP ，或一个大学，甚至一个大学里的系，都可以拥有一个本地域名服务器.当一个主机发出DNS 查询请求时，这个查询请求报文就发送给该主机的本地域名服务器，事实上，我们在Windows 系统中配置"本地连接"时， 就需要填写DNS 服务器地址， 这个地址就是本地DNS 域名服务器的地址。

   ![](../img/network/域名服务器.png)

- 域名解析过程

  域名解析是指把域名映射成为IP 地址或把lP 地址映射成为域名的过程.前者称为正向解析，后者称为反向解析.吨客户端需要域名解析时， 通过本机的DNS 客户端构造一个DN S 请求报文，以UDP 数据报方式发往本地域名服务器。域名解析有两种方式: 递归查询和递归与选代相结合的查询。递归查询的过程如图6-6(a)所示，由于该方法给根域名服务造成的负载过大，所以在实际中几乎不使用。

  ![](../img/network/域名解析.png)

  1. 主机向本地域名服务器的查询采用的是递归查询
  2. 本地域名服务器向根域名服务器的查询采用迭代查询

- 为了提高DNS 的查询效率，并减少因特网上的DNS 查询报文数量，在域名服务器中广泛地使用了高速缓存。当一个DNS 服务器接收到DNS 查询结果时，它能将该DNS 信息缓存在高速缓存中。这样，当另一个相同的域名查询到达该DNS 服务器时，该服务器就能够直接提供所要求的IP 地址，而不需要再去向其他DNS 服务器询问了。因为主机名和IP 地址之间的映射不是永久的，所以DNS 服务器将在一段时间后丢弃高速缓存中的息。

### 5.3，文件传输协议FTP

#### 5.3.1，FTP 的工作原理

- 文件传输协议FTP ( File Transfer Protocol ) 是因特网上使用得最广泛的文件传送协议。FTP提供交互式的访问，允许客户指明文件的类型与格式，井允许文件具有存取权限。它屏蔽了各计算机系统的细节，因而适合于在异构网络中任意计算机之间传选文件.

- FTP 提供以下功能:
  ①提供不同种类主机系统(硬、软件体系等都可以不同〉之间的文件传输能力。
  ②以用户权限管理的方式提供用户对远程FTP 服务器上的文件管理能力。
  ③ 以匿名FTP 的方式提供公用文件共事的能力。

- FTP 采用客户/服务器的工作方式，它使用TCP 可靠的传输服务. 一个FTP 服务器进程可同时为多个客户进程提供服务. FTP 的服务器进程由两大部分组成: 一个主进程，负责接收新的请求:另外有若干个从属进程，负责处理单个请求.其工作步骤如下:

  ①打开熟知端口21 (控制端口) ，使客户进程能够连接上.
  ②等待客户进程发连接请求.
  ③启动从属进程来处理客户进程发来的情求。主进程与从属进程并发执行， 从属进程对客
  户进程的请求处理完毕后即终止。
  ④回到等待状态，继续接收其他客户进程的请求.

- 服务器必须在整个会话期间保留用户的状态信息。特别是服务器必须把指定的用户账户主与控制连接联系起来，服务器必须追踪用户在远程目录树上的当前位置。

#### 5.3.2，控制连接与数据连接

1. FTP 在工作时使用两个井行的TCP 连接 ，一个是控制连接〈端口号21 ) ， 一个是数据连接(端口号20). 使用两个不同的端口号可使协议更加简单和更容易实现.

   ![](../img/network/ftp.png)

2. .控制连接

   服务器监听21号端口，等待客户连接，建立在这个端口上的连接称为控制连接，控制连接用来传输控制信息(如连接请求、传送请求等〉。并且控制信息都是以7 位ASCIl格式传送的。等客户发出的传送请求，通过控制连接发送给服务器端的控制进程，但控制连接并不用来传送文件。在传输文件时还可以使用控制连接(例如，客户在传输中途发一个中止传输的命令)，因此控制连接在整个会话期间一直保持打开状态.

3. 数据连接

   服务器端的控制进程在接收到FTP 客户发送来的文件传输请求后就创建"数据传送进程"和"数据连接"。数据连接用来连接客户端和服务器端的数据传送进程，数据传送进程实际完成文件的传送，在传送完毕后关闭"数据传送连接"并结束运行。

### 5.4，电子邮件

#### 5.4.1，电子邮件系统的组成结构

1. 自从有了困特网，电子邮件就在因特网上流行起来。电子邮件是一种异步通信方式，通信时不需要双方同时在场。电子邮件把邮件发送到收件人使用的邮件服务器，并放在其中的收件人邮箱中，收件人可以随时上网到自己使用的邮件服务器进行读取。一个电子邮件系统应具有图6-8 所示的三个最主要的组成构件，这就是用户代理( Mser Agent) 、邮件服务器和电子邮件使用的协议，如SMTP 、POP3 (或IMAP ) 等。

   ![](../img/network/电子邮件.png)

2. 用户代理UA: 用户与电子邮件系统的接口，用户代理使用户能够通过一个很友好的接口来层发送和接收邮件，用户代理至少应当具有撰写、显示和邮件处理的功能。通常悄况下， 用户代理就是一个运行在PC 上的程序，常见的有Outlook 、Foxmai l 和Thunderbird 等.
   邮件服务器:组成I 电子邮件系统的核心。邮件服务器的功能是发送和接收邮件，同时还要向发信人报告邮件传送的悄况〈己交付、被拒绝、丢失等〉。
   邮件服务器采用客户/服务器方式工作，但它能够同时充当客户和服务器。例如，当邮件服务器A 向邮件服务器B 发选邮件时， A 就作为SMTP 客户，而B 是SMTP 服务器:反之，当B 向A 发送邮件时， B 就是SMTP 客户，而A 就是SMTP 服务器。
   邮件发送协议和读取协议: 邮件发送协议用于用户代理向邮件服务器发送邮件或在邮件服务
   器之间发送邮件，通常使用的是SMTP ; 邮件读取协议用于用户代理从邮件服务器读取邮件， 如
   POP3 (邮局协议的第3 个版本〉。需要注意的是， SMTP 采用的是"推"push ) 的通信方式，即在用户代理向邮件服务器发送邮件以及邮件服务器之间发送邮件时， SMTP 客户端主动将邮件"推"送到SMTP 服务器端。而POP3 采用的是"拉" ( Pull ) 的通信方式，当用户目:取邮件时，用户代理向邮件服务器发出请求，"拉"取用户邮箱巾的邮件。

   ![](../img/network/电子邮件发送和读取.png)

#### 5.4.2，SMTP 协议和POP3 协议

1. SMTP 协议

   简单邮件传输协议( Simple Majl Transfer Protocol. SMTP ) 是一种提供可靠且有效的电子邮件传输的协议，控制两个相互通信的SMTP 进程交换信息。由于SMTP 使用客户/服务器'方式，因此负责发送邮件的SMTP 进程就是S MTP 客户，而负责接收邮件的SMTP 进程就是S MTP 服务器。SMTP 用的是TCP 连接， 端口号25 . SMTP通信有以下三个阶段:

   - 连接建立
   - 邮件发送
   - 连接释放

2. POP3 协议

   1. 邮局协议( Post Office Protocol , POP ) 是一个非常简单、但功能有限的邮件读取协议，现在使用的是它的第3 个版本POP3 . POP3 采用的是"拉" ( Pull ) 的通信方式，当用户读取邮件时，用户代理向邮件服务器发出求，" 拉"取用户邮箱中的邮件。POP 也使用客户/服务器的工作方式，在传输层使用TCP 协议，端口号110 . 在接收方计算机中的用户代理必须运行POP 客户程序，而在接收厅的邮件服务器上则运行POP 服务器程序.POP 有两种工作方式"下载并保留"和"下载并删除模式"，在下载并保留"的模式下，用户从邮件服务器上读取邮件之后，邮件依然会保留在邮件服务器上， 用户下次可以再次从服务器上读取该邮件;而使用"下载并删除"时，邮件一旦被读取之后，就被从邮件服务器上删除了，用户不能再次从服务器七读取了。

   2. 另一个邮件接收协议是网际报文存取协议IMAP ，它比POP 复杂得多，但是目前还只是因特网的建议标准。

### 5.5，万维网WWW

#### 5.5.1，WWW 的概念与组成结构

1. 万维网WWW ( World Wide Web) 是一个资料空间。在这个空间中: 一样有用的事物，称为一样"资源并且由一个全域"统一资源定位符(URL) 标识.这些资源通过超文本传输协议( HTTP ) 传送给使用者，而后者通过点击链接来'获取资源。

2. 万维网的内核部分是由三个标准构成的:

   (1)统一资源定位符(URL) ，负责标识N维网上的各种文档，并使每个文档在整个万维网的范围内具有唯一的标识符URL ，URL 的一般形式是: <协议>://<主机>:<端口>/<路栓〉，常见的〈协议〉有hltp 、ftp 等; <主机〉是存放资源的主机在因特网中的域名，也可以是IP 地址;<端口〉和〈路径〉有时可以省略。在URL中 不区分大小写。

   ( 2 ) 超文本传输协议( Hπ的，它是一个应用层协议，使用TCP 连接进行可靠的传输， HTTP是万维网客户程序和服务器程序之间交互所必须严格遵守的协议.
   (3)超文本标记语言( HTML ) 是一种文档结构的标记语言，使用一些约定的标记对页面上的各种信息(包括文字、卢音、图像、视频等〉、格式进行描述。

#### 5.5.2，超文本传输协议HTTP

- HTTP 协议定义了浏览器〈万维网客户进程)怎样向万维网服务器请求万维网文档，以及服务器怎样把文档传送给浏览器。从层次的角度看， HTTP 是面向事务的(Transacti on- orieoted) 应用层协议， 它规定了在浏览器和服务器之间的请求和响应的格式和规则，它是万维网上能够可靠地交换文件(包括文本、声音、图像等各种多媒体文件〉的重要基础。

1. HTTP 的操作过程

   - 从协议执行过程来说，浏览器要访问WWW 服务器时，首先要完成对WWW 服务器的域名解析。一旦获得了服务器的ip 地址，浏览器将通过TCP 向服务器发送连接建立请求.

   - 万维网的大致工作过程如图6-11 所示。每个万维网站点都有一个服务器进程，它不断地监听TCP 的端口80 (默认) ， 当监听到连接请求后便与浏览器建立连接. TCP 连接边立后，浏览器就向服务器发送请求获取某Web 页面的HTTP请求。服务器收到HTTP 请求后，将构建所请求的Web 页必需的信息， 并通过日HTTP响应返回给浏览器。浏览器再将信息进行解释，然后将Web页显示给用户。最后， TCP 连接释放。

     ![](../img/network/万维网工作过程.png)

   - 在浏览器和服务器之间的请求和响应的交瓦， 必须按照规定的格式和遵循一定的规则，这些格式和规则就是HTTP. 因此HTTP 有两类报文: 请求报文(从Web 客户端向Web 服务器发迭服务请求〉和响应报文(从Wcb 服务器对Web 客户端请求的回答).

     - 用户单击鼠标后所发生的事件按顺序如下(以访问清华大学为例) :
       ( 1 )浏览器分析链接指向页面的URL （ hltp ://WWW.tsinghua. edu.cn !chnlindex.htm ) 。
       ( 2 ) 浏览器向DNS 请求解析www.tsinghua.edu.cn 的ip地址.
       (3)域名系统DN S 解析出清华大学服务器的iP 地址。
       ( 4 ) 浏览器与该服务器建立TCP 连接(默认端口号80 ).
       ( 5 ) 浏览器发出HTTP 请求: GET !chnlindex.htm.
       ( 6 ) 服务器通过HTTP 响应把文件index.htm 发送给浏览器。
       ( 7 ) TCP 连接释放。
       ( 8 ) 浏览器将文件index .htm 进行解释，并将Web 页显示给用户。

2. HTTP 协议的特点

   1. HTTP 协议是无状态的.也就是说，同一个客户第二次访问同一个服务器上的页面时， 服务器的响应与第一次被访问时的相同。因为服务器并不记得曾经访问过的这个客户， 也不记得为该客户曾经服务过多少次。HTTP 的无状态特性简化了服务器的设计，使服务器更容易支持大量并发的HTTP 请求。在实际应用中， 通常使用Cookie 加数据库的方式来跟踪用户的活动〈如记录用户最近浏览的商品等)。Cookie 是一个存储在用户主机中的文本文件，Cookie 面含有一串"识别码"， 如" 1 23456"，用于Web服务识别用户。Web 服务器根据Cookie 就能从数据库中查询到该用户的活动记录， 进而执行一些个性化的工作， 如根据用户之前浏览过的商品向其推荐新产品等。

   2. H TTP 采用TCP 作为运输层协议， 保证了数据的可靠传输. HTTP 不必考虑数据在传输过程中被丢弃后又怎样被重传.但是， HTTP 协议本身是无连接的(请读者务必注意).这就是说，虽然HTTP 使用了TCP 连接，但通信的双方在交换HTIP 报文之前不需要先建立HTTP 连接.

   3. HTTP 既可以使用非持久连接，也可以使用持久连接( HTTP! I . I 支持〉。

      1. 对于非持久连接，每-个网页元素对象(比如一个JPEG 图、FLASH 等〉的传输都需要单独建立一个TCP 连接，如剧6 - 12 所示〈第三次握手的报文段中捎带了客户对万维队| 文挡的请求)。也就是说，请求一个万维网文档所需的时间是该文件的传输时间(与文档大小成正比〉加上两倍往返时间RTT,

      2. 所谓持久连接，是指万维网服务在发送响应后仍然保持这条连接，使同一个客户和服务都可以继续在这条连接上传送后续的HTTP请求与响应报文。

         ![](../img/network/万维网.png)

      3. 持久连接又分为非流水线和流水线两种方式.对于非流水线方式，客户在收到前一个响应后才能发出下一个请求. HTTP/ I. I 的默认方式是使用流水线的持久连接.这中情况下， 客户每遇到一个对象引用就立即发出一个情需求，因而客户可以逐个地连续发出对各个引用对象的请求 . 如果所有的请求和响应都是连续发迭的，那么所有引用的对象共计经历l 个RTT 延迟，而不是像非流水线方式那样，每个弓|用都必须有l 个RTT门延迟。

   4. HttP 的报文结构

      - HttP 是面向文本的(Text.Qriented) .因此报文中的每个字段都是一些ASCIl 码串，并且每个字段的长度都是不确定的. 有两类HttP 报文:

        - 请求报文一一从客户向服务器发送的请求报文，如图6- 14(a)所示。

        - 响应报文一一从服务器到客户的回答，如图6-14(b)所示。

          ![](../img/network/http报文.png)

      - HttP 请求报文和响应报文都是由三个部分组成。从图6-14 可以看出，这两种报文的区别就是开始行不同.

      - 开始行，用于区分是请求报文还是响应报文。在请求报文中的开始行叫做请求行，而在响报文中的开始行叫做状态行.开始行的三个字段之间部以空格分隔开，最后的"CR " 和" LF "分别代表"回车"和"换行，请求报文的"请求行"有三个内容: 方法、请求资源的URL 以及HttP 的版本。其中，"方法"就是对所谓求对象进行的操作，这些方法实际上也就是一些命令.表6-1 给出了HTIP 请求报文中常用的几个方法。

        ![](../img/network/方法.png)

      - 首部行， 用来说明浏览器、服务器或报文上体的一些信息。首部可以有好几行，但可以不使用.在每一个首部行都有首部字段名和它的值，每一行在结束的地方都要有"回车"和"换行“，整个首部结束时，还有一空行将首部行和后面的实体上体分开。

      - 实体主体，在请求报文中一般都不用这个宇段，而在响应报文中也可能没有这个字段。

#### 5.5.3，应用层协议

![](../img/network/应用层协议.png)

   

## 第六章，易错点整理

### 6.1，差错检验

1. 数据链路层的差错控制

   - 由于信道噪声等各种原因，帧在传输过程中可能会出现错误。用以使发送方确定接收方是否正确收到了由它发送的数据的方法称为差错控制。通常，这些错误可分为位错和帧错误。
   - 位错指帧中某些位出现了差错。通常采用循环冗余校验(C RC) 方式发现位错，通过自动重传请求(Automatic Repeat reQuest, ARQ ) 方式来重传出错的帧.具体做法是:让发送方将要发送的数据帧附加一定的CRC 冗余检错码一并发迭，接收方则根据检错码对数据帧进行错误检测，若发现错误， 则丢弃， 发送方超时重传该数据帧.这种差错控制方法就称为ARQ 法， ARQ 法仅返回很少的控制信息，便可有效地确认所发数据帧是否被正确接收.
   - 帧错误是指帧的丢失，重复或失序等错误。在数据链路层引入定时器和编号机制，可以保证每一帧最终都能有且仅有一次正确地交付给目的结点。

2. 传输层的UDP校验

   1. 在计算校验和时，要在UDP 数据报之前增加12个字节的伪首部，伪收部并不是UDP 真正的首部。只是在计算校验和时，临时添加在UDP 数据报的前面，得到一个临时的UDP 数据报。校验和就是按照这个临时的U DP 数据报计算的. 伪首部既不向下传送也不向上递交，而仅仅是为了计算校验和.这样的校验和，既检查了UDP 数据报， 又对IP 数据报的源IP 地址和目的IP地址进行了检验。
   2. UD P 校验和的计算方法和TCP 数据报首部校验和的计算方法相似，都使用二进制反码运算求和再取反。**但不同的是:lP 数据报的校验和只检验lP 数据报的首郁， 但UDP 的校验和是把首部和数据部分一起都检验。**
   3. 在发送方，首先是把全零放入校验和字段并且添加伪首部。然后，把UDP 数据报看成是由许多1 6 位的字串连接起来。若UDP 数据报的数据部分不是偶数个字节，则要在数据部分末尾增加一个全零字节(但此字节不发送〉。接下来就按二进制反码计算出这些16 位字的和.将此和的二进制反码写入校验和字段。在接收方，把收到的UDP 数据报加上伪首部(如果不为偶数个字第节，还需要补上全零字节〉后，按二进制反码计算出这些16 位字的和. 当无差错时其结果应全为1， 否则就表明有差错出现，接收方就应该丢弃这个UDP 数据报。

3. 传输层的TCP校验

   检验和字段检验的范围包括首部和数据这两部分。在计算检验和时，和UDP 一样，要在TCP 报文段的前面加 12 字节的伪首部〈只需将UDP 伪首部的第4 个字段，即协议字段的1 7 改成6 ，其他的和UDP 一样)。

- **在这里注意吧，不管是UDP还是TCP,检验的部分都包括首部和数据部分。**

#### 6.2，每一层的功能总结

1. 物理层：该层包括物理连接媒介，是计算机联网的基础，进行转发比特流。（任何一种调制解调器）
2. 数据链路层：在不可靠的物理线路上进行可靠的数据传递。（ALOHA,PPP,CSMA,CSMA/CD,CDMA）
3. 网络层：实际上是完成主机到主机之间的通信服务，（IP,ARP,RARP,ICMP,OSPF,BGP）
4. 传输层：提供的是端到端的数据通信服务，（TCP,UDP）
5. 会话层：负责在网络中的两个节点之间建立和维持通信。
6. 表示层：为不同终端的上层用户提供数据和信息的格式化标示方法（数据加密解密,XML,HTML）
7. 应用层：负责对软件提供接口以使程序能够使用网络的服务，（注意：不是运行着的那些程序，而是对应用程序提供接口或服务）FTP,HTTP,DNS。


















































## 第六章，面试题总结

1. 拥塞控制

   1. 慢开始
      - 发送方维持一个叫做拥塞窗口`cwnd（congestion window）`的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口，另外考虑到接受方的接收能力，发送窗口可能小于拥塞窗口。
      - 慢开始算法的思路就是，不要一开始就发送大量的数据，先探测一下网络的拥塞程度，也就是说由小到大逐渐增加拥塞窗口的大小。
      - 实时拥塞窗口大小是以字节为单位的。当然收到单个确认但此确认多个数据报的时候就加相应的数值。所以一次传输轮次之后拥塞窗口就加倍。这就是乘法增长，和后面的拥塞避免算法的加法增长比较。
      - 为了防止`cwnd `增长过大引起网络拥塞，还需设置一个慢开始门限`ssthresh `状态变量。`ssthresh` 的用法如下：
        - 当`cwnd<ssthresh `时，使用慢开始算法。
        - 当`cwnd>ssthresh` 时，改用拥塞避免算法。
        - 当`cwnd=ssthresh `时，慢开始与拥塞避免算法任意。
   2. 拥塞避免
      - 拥塞避免算法让拥塞窗缓慢增长，即每经过一个往返时间`RTT` 就把发送方的拥塞窗口`cwnd` 加1，而不是加倍。这样拥塞窗口按线性规律缓慢增长。
      - 无论是在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认，虽然没有收到确认可能是其他原因的分组丢失，但是因为无法判定，所以都当做拥塞来处理），就把慢开始门限`ssthresh` 设置为出现拥塞时的发送窗口大小的一半。然后把拥塞窗口设置为1，执行慢开始算法。
   3. 快重传
      - 快重传要求接收方在收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。
   4. 快恢复
      - 当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把`ssthresh `门限减半。但是接下去并不执行慢开始算法。
      - 考虑到如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方现在认为网络可能没有出现拥塞。所以此时不执行慢开始算法，而是将`cwnd` 设置为`ssthresh `的大小，然后执行拥塞避免算法。

2. 为什么建立连接协议是三次握手，而关闭连接却是四次握手呢？

   - 这是因为服务端的`LISTEN `状态下的`SOCKET `当收到`SYN` 报文的建连请求后，它可以把`ACK`和`SYN`（`ACK `起应答作用，而`SYN` 起同步作用）放在一个报文里来发送。但关闭连接时，当收到对方的`FIN` 报文通知时，它仅仅表示对方没有数据发送给你了；但未必你所有的数据都全部发送给对方了，所以你可以未必会马上会关闭`SOCKET`,也即你可能还需要发送一些数据给对方之后，再发送`FIN `报文给对方来表示你同意现在可以关闭连接了，所以它这里的`ACK `报文和`FIN `报文多数情况下都是分开发送的。

3. 第三次握手失败

   - 当客户端收到服务端的`SYN+ACK `应答后，其状态变为`ESTABLISHED`，并会发送`ACK `包给服务端，准备发送数据了。如果此时`ACK `在网络中丢失，过了超时计时器后，那么`Server`端会重新发送`SYN+ACK` 包，重传次数根据`/proc/sys/net/ipv4/tcp_synack_retries `来指定，默认是5 次。如果重传指定次数到了后，仍然未收到`ACK `应答，那么一段时间后，`Server` 自动关闭这个连接。但是`Client` 认为这个连接已经建立，如果`Client` 端向`Server` 写数据，`Server`端将以`RST`包响应，方能感知到`Server` 的错误。
   - 在`S erver`返回一个确认的`SYN-ACK` 包的时候，S 可能由于各种原因不会接到C 回应的ACK 包。这个也就是所谓的半开放连接，S 需要耗费一定的数量的系统内存来等待这个未决的连接，虽然这个数量是受限，但是恶意者可以通过创建很多的半开放式连接来发动SYN 洪水攻击。攻击者可以通过IP 欺骗发送SYN 包给受害者系统，这个看起来是合法的，但事实上所谓的C 根本不会进行ACK 回应服务端S 的SYN-ACK 报文，这意味着受害者将永远不会接到ACK报文。而此时，半开放连接将最终耗用受害者所有的系统资源（即使等待ACK 包有超时限制），受害者将不能再接收任何其他的请求。

4. 如何应对TCP SYN Flood

   - 第一个参数tcp_synack_retries = 0 是关键，表示回应第二个握手包（SYN+ACK 包）给客户端IP 后，如果收不到第三次握手包（ACK 包）后，不进行重试，加快回收“半连接”，不要耗光资源。
   - 修改这个参数为0 的副作用：网络状况很差时，如果对方没收到第二个握手包，可能连接服务器失败，但对于一般网站，用户刷新一次页面即可。这些可以在高峰期或网络状况不好时tcpdump 抓包验证下。
   - 之所以可以把tcp_synack_retries 改为0，因为客户端还有tcp_syn_retries 参数，默认是5，即使服务器端没有重发SYN+ACK 包，客户端也会重发SYN 握手包。
   - tcp_max_syn_backlog
     从字面上就可以推断出是什么意思。在内核里有个队列用来存放还没有确认ACK 的客户端
     请求，当等待的请求数大于tcp_max_syn_backlog 时，后面的会被丢弃。
   - 所以，适当增大这个值，可以在压力大的时候提高握手的成功率。手册里推荐大于1024。使用服务器的内存资源，换取更大的等待队列长度，让攻击数据包不至于占满所有连接而导致正常用户无法完成握手。
     当半连接的请求数量超过了tcp_max_syn_backlog 时，内核就会启用SYN cookie 机制，不再把半连接请求放到队列里，而是用SYN cookie 来检验。
   - 启用3
     启用之前，服务器在接到SYN 数据包后，立即分配存储空间，并随机化一个数字作为SYN号发送SYN+ACK 数据包。然后保存连接的状态信息等待客户端确认。启用SYN Cookie 之后，服务器不再分配存储空间，而且通过基于时间种子的随机数算法设置一个SYN 号，替代完全随机的SYN 号。发送完SYN+ACK 确认报文之后，清空资源不保存任何状态信息。直到服务器接到客户端的最终ACK 包，通过Cookie 检验算法鉴定是否与发出去的SYN+ACK报文序列号匹配，匹配则通过完成握手，失败则丢弃。当然，前文的高级攻击中有SYN 混合ACK 的攻击方法，则是对此种防御方法的反击，其中优劣由双方的硬件配置决定

5. 客户端收到一个窗口为0 的包怎么处理

   - TCP 长连接与短连接

     TCP 短连接的情况，client 向server 发起连接请求，server 接到请求，然后双方建立连接。client 向server 发送消息，server 回应client，然后一次读写就完成了，这时候双方任何一个都可以发起close 操作，不过一般都是client 先发起close 操作。为什么呢，一般的server不会回复完client 后立即关闭连接的，当然不排除有特殊的情况。从上面的描述看，短连接
     一般只会在client/server 间传递一次读写操作client 向server 发起连接，server 接受client 连接，双方建立连接。Client 与server 完成一次读写之后，它们之间的连接并不会主动关闭，后续的读写操作会继续使用这个连接。

6. 为什么要有time_wait

   1. 可靠的终止TCP 连接。

      可靠的终止TCP 连接，若处于time_wait 的client 发送给server 确认报文段丢失的话，server将在此又一次发送FIN 报文段，那么client 必须处于一个可接收的状态就是time_wait 而不是close 状态。

   2. 保证让迟来的TCP 报文段有足够的时间被识别并丢弃。

      保证迟来的TCP 报文段有足够的时间被识别并丢弃，linux 中一个TCPport 不能打开两次或两次以上。当client 处于time_wait 状态时我们将无法使用此port 建立新连接，假设不存在time_wait 状态，新连接可能会收到旧连接的数据。

   3. 可靠地实现TCP 全双工连接的终止

      TCP 协议在关闭连接的四次握手过程中，最终的ACK 是由主动关闭连接的一端（后面统称A端）发出的，如果这个ACK 丢失，对方（后面统称B 端）将重发出最终的FIN，因此A 端必须维护状态信息（TIME_WAIT）允许它重发最终的ACK。如果A 端不维持TIME_WAIT 状态，而是处于CLOSED 状态，那么A 端将响应RST 报文，B 端收到后将此报文解释成一个错误（在java 中会抛出connection reset 的SocketException)。
      因而，要实现TCP 全双工连接的正常终止，必须处理终止过程中四个报文任何一个报文的
      丢失情况，主动关闭连接的A 端必须维持TIME_WAIT 状态。

   4. 允许老的重复报文在网络中消逝

      TCP 报文可能由于路由器异常而“迷途”，在迷途期间，TCP 发送端可能因确认超时而重发这个报文，迷途的报文在路由器修复后也会被送到最终目的地，这个迟到的迷途报文到达时可能会引起问题。在关闭“前一个连接”之后，马上又重新建立起一个相同的IP 和端口之间的“新连接”，“前一个连接”的迷途重复分组在“前一个连接”终止后到达，而被“新连接”收到了。为了避免这个情况，TCP 协议不允许处于TIME_WAIT 状态的连接启动一个新的可用连接，因为TIME_WAIT 状态持续2MSL，就可以保证当成功建立一个新TCP 连接的时候，来自旧连接重复分组已经在网络中消逝。

7. 客户端和服务器都可能会进入time_wait

   - 高并发TCP 服务器中进行主动关闭的一方最好是客户端：因为对于高并发服务器来说文件描述符资源是很重要的资源，如果对于每一个连接都要经历TIME_WAIT 这个2MSL 的时长，势必造成资源不能立马复用的浪费。虽然对于客户端来说TIME_WAIT 状态会占用端口和句柄资源，但是客户端一般很少有并发资源限制，所以客户端执行主动关闭是比较合适的。

   - TIME_WAIT 状态到底会占用什么？

     被占用的是一个五元组：（协议，本地IP，本地端口，远程IP，远程端口）。对于Web 服务器，协议是TCP，本地IP 通常也只有一个，本地端口默认的80 或者443。只剩下远程IP 和远程端口可以变了。如果远程IP 是相同的话，就只有远程端口可以变了。这个只有几万个，所以当同一客户端向服务器建立了大量连接之后，会耗尽可用的五元组导致问题。

8. 客户端断开连接造成time_wait 影响

   - 客户端：
     客户端与服务端进行短连接的TCP 通信，如果在同一台机器上进行压力测试模拟上万的客户请求，并且循环与服务端进行短连接通信，那么这台机器将产生4000 个左右的TIME_WAITsocket，后续的短连接就会产生address already in use : connect 的异常。如果是客户端发起了连接，传输完数据然后主动关闭了连接，这时这个连接在客户端就会处于TIMEWAIT 状态，同时占用了一个本地端口。如果客户端使用短连接请求服务端的资源或者服务，客户端上将有大量的连接处于TIMEWAIT 状态，占用大量的本地端口。最坏的情况就是，本地端口都被用光了，这时将无法再建立新的连接。

9. 客户端断开连接造成time_wait 解决

   - 客户端：

   1. 使用长连接，如果是http，可以使用keepalive
   2. 增加本地端口可用的范围，比如Linux 中调整内核参数：net.ipv4.ip_local_port_range
   3. tcp_tw_reuse 参数用来设置是否可以在新的连接中重用TIME_WAIT 状态的套接字。注
       意，重用的是TIME_WAIT 套接字占用的端口号，而不是TIME_WAIT 套接字的内存等。这个
       参数对客户端有意义，在主动发起连接的时候会在调用的inet_hash_connect()中会检查是否
       可以重用TIME_WAIT 状态的套接字。如果你在服务器段设置这个参数的话，则没有什么作
       用，因为服务器端ESTABLISHED 状态的套接字和监听套接字的本地IP、端口号是相同的，
       没有重用的概念。但并不是说服务器端就没有TIME_WAIT 状态套接字。

   - 服务器：
     不像客户端有端口限制， 处理大量TIME_WAIT Linux 已经优化很好了， 每个处于
     TIME_WAIT 状态下连接内存消耗很少，
     而且也能通过tcp_max_tw_buckets = 262144 配置最大上限，现代机器一般也不缺这点内存。
     tcp_timestamps 参数用来设置是否启用时间戳选项，tcp_tw_recycle 参数用来启用快速回收
     TIME_WAIT 套接字。tcp_timestamps 参数会影响到tcp_tw_recycle 参数的效果。如果没有时
     间戳选项的话，tcp_tw_recycle 参数无效

10. 客户端收到ConnectionReset

    - server 端主动发起了断连
      导致“Connection reset”的原因是服务器端因为某种原因关闭了Connection，而客户端依然
      在读写数据， 此时服务器会返回复位标志“RST” ， 然后此时客户端就会提示
      “java.net.SocketException: Connection reset”。
      服务器返回了“RST”时，如果此时客户端正在从Socket 套接字的输出流中读数据则会提示
      Connection reset”；
      服务器返回了“RST”时，如果此时客户端正在往Socket 套接字的输入流中写数据则会提示
      “Connection reset by peer”。

11. UDP 可靠传输

    - 实现一个最基础的可靠udp 通讯协议，我们只需要提供一个重传机制即可。在这我实现了
      一个简单的可靠udp 协议，这个协议为每一个发送出去的udp 数据包分配一个包id，每次
      接收方收到一个数据包时，都要回应发送方一个ack 对应这个包id。协议通过这种确认机制
      来保证接收方能收到发送方发出的udp 数据包，在发出的时候，发送方应该设置一个计时
      器，超时的话会重传数据包。

    - 具体来说它没做这些事情：

      它没有保证包的有序性。发送方连续发送几个udp 数据包，接收方可以以任何顺序收到这
      几个数据包。如果想要做到有序性，必须由应用层来完成。
      它没做流量控制。发送方连续大量发送数据包会导致网络性能变差，丢包次数增大。
      它没对数据包大小做控制。为了避免IP 层对数据包进行分片，应用层应该要保证每个数据
      包的大小不超过MTU。如果这个数据包会经过广域网（一般情况下）这个值应该不超过576。
      考虑到IP 头的20 字节，udp 头的8 个字节，以及这个协议头的字节。最好每次发送的数据大小在512m以内。

12. socket 选项TCP_NODELAY在网络拥塞控制领域，有一个非常有名的算法叫做Nagle 算法（Nagle algorithm），这是
    使用它的发明人John Nagle 的名字来命名的，John Nagle 在1984 年首次用这个算法来尝
    试解决福特汽车公司的网络拥塞问题（RFC 896）。
    该问题的具体描述是：如果我们的应用程序一次产生1 个字节的数据，而这个1 个字节数
    据又以网络数据包的形式发送到远端服务器，那么就很容易导致网络由于太多的数据包而过
    载。比如，当用户使用Telnet 连接到远程服务器时，每一次击键操作就会产生1 个字节数
    据，进而发送出去一个数据包，所以，在典型情况下，传送一个只拥有1 个字节有效数据
    的数据包，却要发费40 个字节长包头（即ip 头20 字节+tcp 头20 字节）的额外开销，这
    种有效载荷（payload）利用率极其低下的情况被统称之为愚蠢窗口症候群（Silly Window
    Syndrome）。可以看到，这种情况对于轻负载的网络来说，可能还可以接受，但是对于重
    负载的网络而言，就极有可能承载不了而轻易的发生拥塞瘫痪。

    针对上面提到的这个状况，Nagle 算法的改进在于：如果发送端欲多次发送包含少量字符的
    数据包（一般情况下，后面统一称长度小于MSS 的数据包为小包，与此相对，称长度等于
    MSS 的数据包为大包，为了某些对比说明，还有中包，即长度比小包长，但又不足一个MSS
    的包），则发送端会先将第一个小包发送出去，而将后面到达的少量字符数据都缓存起来而
    不立即发送，直到收到接收端对前一个数据包报文段的ACK 确认、或当前字符属于紧急数
    据，或者积攒到了一定数量的数据（比如缓存的字符数据已经达到数据包报文段的最大长度）
    等多种情况才将其组成一个较大的数据包发送出去。
    设置NODELAY 会立即发送，不会延迟。

13. 如何解决tcp 粘包问题

    面向流的协议 
    1）数据包固定大小，每收到该大小字节视为一个包
    2）分隔符，比如\r\n
    3）自定义数据包，header 中指定body 的长度（最常使用）

 

   



